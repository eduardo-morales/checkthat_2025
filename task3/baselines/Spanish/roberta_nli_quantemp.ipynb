{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## es para generar un clasificador como baseline. El problema es que en ingles utiliza la pregunta\n",
        "## se debe entrenar para español sin utilizar la pregunta, solo doc + claim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egtdWTvcOeTy",
        "outputId": "731ee16b-c89f-4ddd-a65b-1f2a9b140fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AlOzas-OzjA",
        "outputId": "15904d10-17d5-4e0d-c893-ef7dba02fe33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.51.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\edu\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (3.4.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.3; however, version 25.1.1 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\Edu\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQgFwRXu0_U6",
        "outputId": "b205b974-6854-40df-f5f6-7b66151994da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.30.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (2024.12.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: requests in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (3.0.12)\n",
            "Requirement already satisfied: colorama in c:\\users\\edu\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface_hub) (2019.11.28)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface_hub) (2.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface_hub) (2.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.3; however, version 25.1.1 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\Edu\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub\n",
        "from huggingface_hub import notebook_login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331,
          "referenced_widgets": [
            "7eb5d9cacc6c41a58994a1615a44d086",
            "c78a28c25acc4f9b87392719681101cd",
            "9b51530a76f94da4ae27a7f25cf27ee3",
            "d1ef085b43794d1bb4f92acbd5f6f634",
            "fa555a2e0115487599c31d2368b83fff",
            "e379ef253a774d6e8125ee20495813f4",
            "91c3323870d64d82b858dd723baeba89",
            "8955b698cf2340e58d523a6f03e0026c",
            "e31fd0b45a8546e0be873fc56d35959f",
            "a8203576ad384b88895f72ee923c5ca7",
            "7ca9f4424bae4460a9850d4f6ff4da18",
            "d849148804c747c8aba9cbda38accd67",
            "be2b1c33c0d54cd2a2e39cf52ec70957",
            "4bdc157bf7b3479b918cb087c4804bdc",
            "614599e3e614429ab0b97c69081a0e18",
            "ffd4ff391ded454299848594a048f6c7",
            "43cb251e9222448a900f03c42e58592d"
          ]
        },
        "id": "ayFV2esI1DsP",
        "outputId": "c614d229-cf0c-4acd-f9eb-293889806218"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f3a6d98e24b4c19a4d12f76000a723e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "notebook_login()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "a356d976c5bc437aba9ef1964dffbccb",
            "a63bab1fbb7f47c08404c2c8e576c8ab",
            "e1c27f82724d40179ecb939f1bcf3e19",
            "41ad5d582748475e934bd6d7bbc6db88",
            "057f6824b04047b9a64bd33c13374fdc",
            "0a407fbab91d416dad54911ca5ae34f2",
            "6a6eba5085eb4de0939d33d7b9140612",
            "c4563c6693d943f0923dd1db90609bfb",
            "069fac70741e46aa8455c3c68e286148",
            "2dd91549d6fc42d5a5bea3df78df29be",
            "e962acc9f7944bd6a14a899d27e5825c",
            "ab72101a46d64a199383b4855ba969a6",
            "0d7f346bdfd1408fa34dbc0dd383a2e9",
            "a5ff5c0f2e07418aace9422001961472",
            "3e64febdc47d48ef9a185fcb5e4ce81e",
            "0636f2033560480bb67985b0128a6174",
            "7423e1a60ba34753bb14954981e6f62b",
            "df59719e8bf44e1bb349f98674efefa6",
            "db1d477460f14fce85dc2b9c3bb089e3",
            "e9c03217bf794c309381666a45b26804",
            "457c1f1c50aa42c3b01e9d50fdd0ec8f",
            "ce09d6c4222640148d668939bab5008e",
            "483ad42b17b8441880d908d711e0c3b5",
            "0f55c98cc4b14bbb86e5d7eecef4dd65",
            "ad6ac6b0974e4699996289653def8861",
            "27d070e0bc0f43afb42d9f18f0b13b6e",
            "fcadec008dc54e6583a800b746d7a001",
            "005aecb9af7446aab0512347fc4faf1e",
            "ca4b25ceac5c4b6c813ac9fa59b2ddce",
            "1925cff7d7544e069040f271537df7a8",
            "8a73d2714c1342b1ab1185a74fef6198",
            "1db03cf091254bb6bab2c88f76916146",
            "222e80b8c42d481da3a75a24960e74ad",
            "31ade0d811df4904b4de6a75a9eb3898",
            "d7f67153d4104250a073b6f5eca34007",
            "59620c8d958f4e2482fb8c5cf679a3b7",
            "6e1218c6af9c4fec8c43fbcbd0d7b961",
            "9673bee129574b1db39a8bf6dfa79be1",
            "e8158a7b594e42b29a18c54aefd2c045",
            "70b7cd65577f4afaaac2dc9b5ae121c7",
            "0ccf64e07be7473bad93cef52cd9d39c",
            "3ceb6758d9634a1197376d4e27f5e615",
            "678d8a2512484175b923785849fbd605",
            "4272c15544ac483f99cfeb9c2046e2fa"
          ]
        },
        "id": "C_-uxEt3O1Y_",
        "outputId": "38e9a0a3-c4e5-489b-e3b8-b9bb5f3aa044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading roBERT tokenizer...\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer,AutoModel, RobertaTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading roBERT tokenizer...')\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A84PEHj6k13e",
        "outputId": "bf33bdb3-9d14-47cf-e8a7-623b7b9d66d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1506"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json #English/test_set_english_claim.json\n",
        "with open(\"../../data/Spanish/train_spanish_claims.json\", encoding='utf-8') as f:\n",
        "  data = json.load(f)\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "#data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 1204\n",
            "Test size: 302\n"
          ]
        }
      ],
      "source": [
        "# split test_data \n",
        "# Calculate split index\n",
        "split_index = int(0.8 * len(data))\n",
        "\n",
        "# Split the data\n",
        "train_data = data[:split_index]\n",
        "val_data = data[split_index:]\n",
        "print(f\"Train size: {len(train_data)}\")\n",
        "print(f\"Test size: {len(val_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'claim': 'Correos te pide 1,4€ por desinfectarte los paquetes',\n",
              " 'crawled_date': '2020-04-25',\n",
              " 'country_of_origin': 'spain',\n",
              " 'doc': ' | 6 min lectura Nos habéis preguntado por otro mensaje relacionado con la marca española de automóviles SEAT y respiradores. En este habla un supuesto trabajador en nombre del empresa diciendo que la automovilística está esperando a que los hospitales españoles les pidan respiradores, y ofrecería un manual de instrucciones de los mismos. Adjunta además una dirección de correo electrónico y un teléfono. Este mensaje es falso. Así lo ha desmentido la compañía a Newtral.es. Ni han lanzado ninguna campaña similar, ni están teniendo problemas de distribución de los aparatos sanitarios. Una cadena de WhatsApp supuestamente proveniente de la Guardia Civil recomienda desinstalar la aplicación de videoconferencia Zoom, además de eliminar la cuenta. La cadena adjunta un tuit enviado por la cuenta oficial de la Guardia Civil. Sin embargo el tuit no dice eso, por tanto se trata de un mensaje falso. La pregunta a Dulceida en el Orgullo sacada de contexto La Guardia Civil tuiteó este 10 de abril que este mensaje de WhatsApp es un bulo “que aprovecha un tuit de la Guardia Civil y la actualización de seguridad de Zoom para usuarios de Windows para generar alarma social”. Es decir, que el tuit citado por la cadena no decía nada lo que contiene el texto. Circula por diferentes redes sociales un audio criticando al Gobierno en su gestión de la crisis sanitaria. El archivo va acompañado de un texto que asegura que el autor del mensaje grabado es el exministro socialista del Interior José Luis Corcuera. Ese dato es falso: se trata de un locutor de radio. Walter García Carro publicó un tuit reclamando la autoría del audio viral. En otro post de esta red social publicó un link a una plataforma en la que está colgado el programa entero al que pertenece el fragmento que tanto se ha viralizado. Desde fármacos hasta remedios caseros: los mitos sobre cómo evitar la resaca que contradicen la evidencia científica Nos preguntáis por una serie de mensajes que atribuyen al Gobierno la autoría y difusión de unas líneas temporales que mostrarían cuándo podrían ir reabriendo los comercios. Son falsas: no han salido del Gobierno. Un archivo compartido por WhatsApp llamado Fechas de apertura: (calendario tentativo que maneja el gobierno) es falsamente atribuido al Gobierno. Así nos lo han desmentido fuentes del propio organismo a Newtral.es. Circula un mensaje de Correos que solicita el pago de 1,40 euros para desinfectar tu paquete antes de recibirlo. Este mensaje es falso: se trata de phishing, una técnica para robar datos bancarios. Correos jamás pedirá pagos de ninguna cantidad a través de email o SMS. Siempre lo harán en la oficina o en el momento de la entrega. Circula por redes sociales un vídeo situado en Hungría según algunas versiones y en España según otras. También se dice que esas imágenes fueron grabadas durante los estados de alarma de los respectivos países por el coronavirus. ¿Qué hay de cierto en estos textos? Nada. El contexto que se le da estas imágenes es falso. En Bakú, capital de Azerbaiyán, se produjo el pasado 19 de octubre una manifestación contra la corrupción y en solicitud de unas elecciones libres. La policía azerí respondió con al menos 60 detenciones. De ahí es donde se sacaron las imágenes que se comparten como húngaras o españolas. Circula un mensaje por WhatsApp con pautas a seguir en caso de fallecimiento de un familiar por COVID-19. Mucha de la información que se da es errónea. Entre otras cosas, el mensaje asegura que la COVID-19 es una enfermedad profesional. El Real Decreto 1299/2006 recoge las consideradas enfermedades profesionales, y el coronavirus no se encuentra entre ellas. Circula un documento con un sello de la Guardia Civil con supuestos procedimientos que deben seguir algunos negocios, como el del taxi o el de la peluquería; o regulaciones tales como la prohibición del uso de espacios comunes entre vecinos. Este documento, sin embargo, es falso. Así lo ha desmentido la Guardia Civil en su cuenta oficial de Twitter, adjuntando un link al auténtico Real Decreto que establece qué actividades se pueden desarrollar y en qué condiciones. Recuerda que los pantallazos, fotografías y demás copias se pueden manipular. Si quieres conocer este tipo de informaciones, acude sola y directamente a fuentes oficiales. Un vídeo compartido más de mil veces en Facebook muestra a un hombre que se corta el cuello mientras huye de la policía. El título del vídeo lleva a pensar que ha sido grabado en España y afirma que es durante la cuarentena. Ambos datos son falsos: ni sucede en España, ni es actual. Varios medios serbios publicaron un suicidio de un hombre mientras huía de la policía serbia por la calle Alejandro I de Yugoslavia durante el pasado mes de enero, época durante la cual Serbia no había registrado casos de coronavirus ni estaba, mucho menos, en estado de alarma. Circula por WhatsApp una captura de pantalla de otro mensaje de la misma aplicación de mensajería que afirma que “a partir del lunes” la Junta de Extremadura permitirá salir a pasear por las avenidas. A continuación viene un link, el cual, al ser una captura de pantalla, no se puede pinchar. Al introducir la dirección en el navegador, vemos que es broma. Por tanto, el mensaje es falso. Pese a que el link del mensaje lleve a una imagen de un gorila, nos hemos puesto en contacto con la Junta, desde donde nos confirman que se trata de un bulo.',\n",
              " 'fact_source': 'newtral',\n",
              " 'factchecker': ['Por Newtral'],\n",
              " 'label': 'False',\n",
              " 'url': 'https://www.newtral.es/covid-19-epidemia-mundial-de-bulos-2/20200425/',\n",
              " 'lang': 'es',\n",
              " 'numerical': True,\n",
              " 'taxonomy_label': 'statistical'}"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "A96MxV43kwaS"
      },
      "outputs": [],
      "source": [
        "val_claims = []\n",
        "for fact in val_data:\n",
        "        strencode = fact[\"claim\"].encode(\"ascii\", \"ignore\")\n",
        "        strdecode = strencode.decode()\n",
        "        val_claims.append(strdecode.lower().strip())\n",
        "\n",
        "train_claims = []\n",
        "for fact in train_data:\n",
        "        strencode = fact[\"claim\"].encode(\"ascii\", \"ignore\")\n",
        "        strdecode = strencode.decode()\n",
        "        train_claims.append(strdecode.lower().strip())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjKHl1Nklpxi",
        "outputId": "51190a12-fa46-443a-afb3-32363826450d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "377"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(val_claims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1506"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_claims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import json\n",
        "# with open(\"../../data/English/train_claims_quantemp.json\") as f:\n",
        "#   train_data = json.load(f)\n",
        "# len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "-SLsXKAUlcu7"
      },
      "outputs": [],
      "source": [
        "# train_claims = []\n",
        "# for fact in train_data:\n",
        "#         strencode = fact[\"claim\"].encode(\"ascii\", \"ignore\")\n",
        "#         strdecode = strencode.decode()\n",
        "#         train_claims.append(strdecode.lower().strip())\n",
        "# '''\n",
        "# for claim in train_claims:\n",
        "#   if claim in test_claims:\n",
        "#     print(claim)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISKaA20X5XJq",
        "outputId": "b9b29a83-ed95-4814-fea2-ce69a871e70a"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# with open(\"../../data/English/decomposed_questions_with_mapped_bm25_evidence/train_claimdecomp_evidence_question_mapping.json\") as f:\n",
        "#   train_data = json.load(f)\n",
        "# len(train_data\n",
        "#     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0apWnqA85eep",
        "outputId": "4aaeca9c-0771-4621-8fdc-a51ab2b6a33c"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# with open(\"../../data/English/decomposed_questions_with_mapped_bm25_evidence/val_claimdecomp_evidence_question_mapping.json\") as f:\n",
        "#   val_data = json.load(f)\n",
        "# len(val_data\n",
        "#     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD0NZfDFkvW1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT-q3h48kxdg",
        "outputId": "00f66565-df9d-4357-a283-6d03de807438"
      },
      "outputs": [],
      "source": [
        "\n",
        "#val_data[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "7cYv6F4Nk4SJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "LE = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "3XKkVcC8lF6t"
      },
      "outputs": [],
      "source": [
        "def get_features(data2):\n",
        "  features = []\n",
        "  for index, fact in enumerate(data2):\n",
        "    claim = fact[\"claim\"]\n",
        "    evidences = []\n",
        "    #for doc in fact[\"docs\"]:\n",
        "      #if len(question[\"top_k_doc\"])>0:\n",
        "    #evidences.append(doc)\n",
        "    evidences.append(fact[\"doc\"])\n",
        "      #questions.append(question[\"questions\"])\n",
        "    #questions = list(set(questions))\n",
        "    evidences = list(set(evidences))\n",
        "    feature = \"[Claim]:\"+claim+\"[Evidences]:\"+\" \".join(evidences)\n",
        "    features.append(feature)\n",
        "  return features\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'claim': 'Correos te pide 1,4€ por desinfectarte los paquetes',\n",
              " 'crawled_date': '2020-04-25',\n",
              " 'country_of_origin': 'spain',\n",
              " 'doc': ' | 6 min lectura Nos habéis preguntado por otro mensaje relacionado con la marca española de automóviles SEAT y respiradores. En este habla un supuesto trabajador en nombre del empresa diciendo que la automovilística está esperando a que los hospitales españoles les pidan respiradores, y ofrecería un manual de instrucciones de los mismos. Adjunta además una dirección de correo electrónico y un teléfono. Este mensaje es falso. Así lo ha desmentido la compañía a Newtral.es. Ni han lanzado ninguna campaña similar, ni están teniendo problemas de distribución de los aparatos sanitarios. Una cadena de WhatsApp supuestamente proveniente de la Guardia Civil recomienda desinstalar la aplicación de videoconferencia Zoom, además de eliminar la cuenta. La cadena adjunta un tuit enviado por la cuenta oficial de la Guardia Civil. Sin embargo el tuit no dice eso, por tanto se trata de un mensaje falso. La pregunta a Dulceida en el Orgullo sacada de contexto La Guardia Civil tuiteó este 10 de abril que este mensaje de WhatsApp es un bulo “que aprovecha un tuit de la Guardia Civil y la actualización de seguridad de Zoom para usuarios de Windows para generar alarma social”. Es decir, que el tuit citado por la cadena no decía nada lo que contiene el texto. Circula por diferentes redes sociales un audio criticando al Gobierno en su gestión de la crisis sanitaria. El archivo va acompañado de un texto que asegura que el autor del mensaje grabado es el exministro socialista del Interior José Luis Corcuera. Ese dato es falso: se trata de un locutor de radio. Walter García Carro publicó un tuit reclamando la autoría del audio viral. En otro post de esta red social publicó un link a una plataforma en la que está colgado el programa entero al que pertenece el fragmento que tanto se ha viralizado. Desde fármacos hasta remedios caseros: los mitos sobre cómo evitar la resaca que contradicen la evidencia científica Nos preguntáis por una serie de mensajes que atribuyen al Gobierno la autoría y difusión de unas líneas temporales que mostrarían cuándo podrían ir reabriendo los comercios. Son falsas: no han salido del Gobierno. Un archivo compartido por WhatsApp llamado Fechas de apertura: (calendario tentativo que maneja el gobierno) es falsamente atribuido al Gobierno. Así nos lo han desmentido fuentes del propio organismo a Newtral.es. Circula un mensaje de Correos que solicita el pago de 1,40 euros para desinfectar tu paquete antes de recibirlo. Este mensaje es falso: se trata de phishing, una técnica para robar datos bancarios. Correos jamás pedirá pagos de ninguna cantidad a través de email o SMS. Siempre lo harán en la oficina o en el momento de la entrega. Circula por redes sociales un vídeo situado en Hungría según algunas versiones y en España según otras. También se dice que esas imágenes fueron grabadas durante los estados de alarma de los respectivos países por el coronavirus. ¿Qué hay de cierto en estos textos? Nada. El contexto que se le da estas imágenes es falso. En Bakú, capital de Azerbaiyán, se produjo el pasado 19 de octubre una manifestación contra la corrupción y en solicitud de unas elecciones libres. La policía azerí respondió con al menos 60 detenciones. De ahí es donde se sacaron las imágenes que se comparten como húngaras o españolas. Circula un mensaje por WhatsApp con pautas a seguir en caso de fallecimiento de un familiar por COVID-19. Mucha de la información que se da es errónea. Entre otras cosas, el mensaje asegura que la COVID-19 es una enfermedad profesional. El Real Decreto 1299/2006 recoge las consideradas enfermedades profesionales, y el coronavirus no se encuentra entre ellas. Circula un documento con un sello de la Guardia Civil con supuestos procedimientos que deben seguir algunos negocios, como el del taxi o el de la peluquería; o regulaciones tales como la prohibición del uso de espacios comunes entre vecinos. Este documento, sin embargo, es falso. Así lo ha desmentido la Guardia Civil en su cuenta oficial de Twitter, adjuntando un link al auténtico Real Decreto que establece qué actividades se pueden desarrollar y en qué condiciones. Recuerda que los pantallazos, fotografías y demás copias se pueden manipular. Si quieres conocer este tipo de informaciones, acude sola y directamente a fuentes oficiales. Un vídeo compartido más de mil veces en Facebook muestra a un hombre que se corta el cuello mientras huye de la policía. El título del vídeo lleva a pensar que ha sido grabado en España y afirma que es durante la cuarentena. Ambos datos son falsos: ni sucede en España, ni es actual. Varios medios serbios publicaron un suicidio de un hombre mientras huía de la policía serbia por la calle Alejandro I de Yugoslavia durante el pasado mes de enero, época durante la cual Serbia no había registrado casos de coronavirus ni estaba, mucho menos, en estado de alarma. Circula por WhatsApp una captura de pantalla de otro mensaje de la misma aplicación de mensajería que afirma que “a partir del lunes” la Junta de Extremadura permitirá salir a pasear por las avenidas. A continuación viene un link, el cual, al ser una captura de pantalla, no se puede pinchar. Al introducir la dirección en el navegador, vemos que es broma. Por tanto, el mensaje es falso. Pese a que el link del mensaje lleve a una imagen de un gorila, nos hemos puesto en contacto con la Junta, desde donde nos confirman que se trata de un bulo.',\n",
              " 'fact_source': 'newtral',\n",
              " 'factchecker': ['Por Newtral'],\n",
              " 'label': 'False',\n",
              " 'url': 'https://www.newtral.es/covid-19-epidemia-mundial-de-bulos-2/20200425/',\n",
              " 'lang': 'es',\n",
              " 'numerical': True,\n",
              " 'taxonomy_label': 'statistical'}"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "qY7Gux6Yn5rI"
      },
      "outputs": [],
      "source": [
        "train_features = get_features(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ5AoF54oV2t",
        "outputId": "7867da60-f74f-4715-b1c1-8926f8ede44e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1204"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "FHml9DUHn_bh",
        "outputId": "fc92676b-7bf7-4e74-e1aa-dcb86dbb41fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[Claim]:Una pareja senegalesa inventó 18 hijos y defraudó 360.000 euros en ayudas sociales en España[Evidences]:\"Recordáis la pareja senegalesa que defraudó 360.000 € en ayudas, fingiendo tener 18 hijos. Pues la han condenado a pagar dos euros. Si fueran españoles, van 10 años a la cárcel\". Con mensajes como este se difunde el caso de una pareja que fingió tener 18 hijos y defraudó 360.000 euros en ayudas sociales afirmando que es senegalesa y que ocurrió en España. Es un bulo: el caso ocurrió en Sunderland (Reino Unido) y la pareja no es senegalesa, sino inglesa.  Una foto publicada por medios ingleses de la pareja, Tracy Ashbridge y Robert Ashbridge de Sunderland, Inglaterra, condenados por fraude de 360.000 euros en ayudas sociales.  El caso ocurrió en Sunderland (Reino Unido) y la pareja no es senegalesa, sino inglesa  Estos contenidos se difunden con capturas de titulares en medios donde no se afirma ni la nacionalidad de los acusados ni el lugar en el que ocurrió. Pero es un caso que ocurrió en Inglaterra. La acusada, Tracy Ashbridge es funcionaria en la Agencia de Recaudación y Aduanas de Su Majestad (HMRC por sus siglas en inglés), que es similar a la Agencia Tributaria en España. Utilizó su posición en el trabajo para alterar los datos de antiguos demandantes legítimos para conseguir dinero, según el medio inglés Sunderland Echo. Ashbridge utilizó un total de nueve cuentas bancarias para recibir los pagos entre 2015 y 2019.  El Tribunal de la Corona de Newcastle condenó a la mujer y a su marido, Robert Ashbridge, ambos ingleses, a devolver solo dos libras, lo que equivale a cerca de cuatro euros, según mencionó el Daily Mail.  Por lo tanto, es un bulo, no está relacionado con la inmigración ni con España: el caso ocurrió en Sunderland (Reino Unido) y la pareja no es senegalesa, sino inglesa.'"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_features[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "SeHEwL3doMD6"
      },
      "outputs": [],
      "source": [
        "val_features = get_features(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ-ipHaHoiY-",
        "outputId": "23a44b5f-7ae4-4128-8926-135607b2d3b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "302"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(val_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Iyh75sm2ok_6",
        "outputId": "b717a62e-0ed3-4c61-c654-cf3a6def966b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[Claim]:Tomado de una cámara instalada en una de las casas donde ocurrió la erupción del volcán de Isla Blanca en Nueva Zelanda el 9 de diciembre del 2019 donde 18 personas perdieron la vida[Evidences]: | 2 min lectura Está volviendo a circular por redes sociales un vídeo que supuestamente muestra la erupción del volcán Isla Blanca, en Nueva Zelanda. Las imágenes compartidas exhiben un mar tranquilo en el que de repente se produce una explosión submarina que genera una nube de humo que se expande rápidamente y acaba cegando la cámara. Sin embargo, el vídeo no es real, sino que se trata de una simulación. También nos habéis enviado a través de nuestro servicio de verificación por WhatsApp (+34 627 28 08 15) estas mismas imágenes acompañadas de un mensaje que indica que se trata de un vídeo “tomado de una cámara instalada en una de las casas donde ocurrió la erupción del volcán de Isla Blanca el 9 de diciembre del 2019, donde 18 personas perdieron la vida”. Es cierto que el 9 de diciembre de 2019 se produjo en Nueva Zelanda la erupción del volcán Isla Blanca, que provocó la muerte de más de 20 personas. Pero el vídeo compartido no muestra este hecho, sino que se trata de una simulación en 3D para el Museo Memorial de la Guerra de Auckland. El vídeo no muestra la erupción del volcán Isla Blanca, en Nueva Zelanda Este mismo bulo ya lo desmentimos en Newtral.es en febrero de 2020. Se trata de una simulación 3D realizada para el Museo Memorial de la Guerra de Auckland, y que hemos encontrado publicado por primera vez hace diez años. Este mismo vídeo puede ser encontrado en la cuenta de Vimeo de la empresa Brandspank, publicado en 2011. En la descripción del mismo explican que se trata de un vídeo diseñado “para simular la vista de un salón de Auckland” que muestra “una representación realista de un evento catastrófico”. La misma secuencia se puede encontrar en el canal de YouTube del Museo Memorial de la Guerra de Auckland. El vídeo fue publicado el 19 de diciembre de 2019 y en la descripción del mismo se indica que se trata de “una simulación educacional de un terremoto causado por una erupción volcánica”. Este vídeo forma parte de la exposición de volcanes del museo, como se puede comprobar en la misma web de la institución. Sobre esta pieza, el museo invita a sentarse “en el salón del 7A Puia St, St Heliers” y observar “una terrorífica erupción en el puerto de Auckland desde una casa”. La erupción del volcán Isla Blanca Sí que es cierto, como se indica en el mensaje que acompaña a este vídeo, que el 9 de diciembre de 2019 el volcán de Isla Blanca entrase en erupción, matando a varias personas. My god, White Island volcano in New Zealand erupted today for first time since 2001. My family and I had gotten off it 20 minutes before, were waiting at our boat about to leave when we saw it. Boat ride home tending to people our boat rescued was indescribable. #whiteisland pic.twitter.com/QJwWi12Tvt — Michael Schade (@sch) December 9, 2019 Según indica la BBC, en el momento de la erupción del volcán Isla Blanca “había unas 50 personas cerca del lugar, incluso caminando cerca del cráter”. En un primer momento se anunciaron 16 fallecidos, y 20 personas se encontraban en cuidados intensivos. Pero en noviembre de 2020 la policía de Nueva Zelanda añadió un nuevo fallecido a causa de las heridas provocadas por la erupción del volcán, llegando a 22 el número de fallecidos por la erupción.'"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_features[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['claim', 'crawled_date', 'country_of_origin', 'doc', 'fact_source', 'factchecker', 'label', 'url', 'lang', 'numerical', 'taxonomy_label'])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "98BSyfIZontr"
      },
      "outputs": [],
      "source": [
        "train_labels = [fact[\"label\"] for fact in train_data]\n",
        "val_labels = [fact[\"label\"] for fact in val_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJYf-sJ4pHCd",
        "outputId": "621cbd28-c0d2-4849-c08d-07d8cb793ac4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 1, 1, 1], dtype=int64)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels_final = LE.fit_transform(train_labels)\n",
        "train_labels_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cjPop6cpdiA",
        "outputId": "832584fd-0ada-4b9c-b594-ee080c32b21a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
              "      dtype=int64)"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels_final[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dO586pApTPH",
        "outputId": "c1d079a7-80ff-424b-d428-e7c07b562aa3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
              "       2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 0, 1, 0, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "       2, 1, 1, 0, 2, 2, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 2, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1,\n",
              "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1,\n",
              "       1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 2, 1, 1, 0, 1, 2, 0,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1])"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_labels_final = LE.transform(val_labels)\n",
        "val_labels_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDzDVC1lnmwD",
        "outputId": "40f26153-87d4-4180-cdef-8ad006a4bc2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'claim': 'ABC tuitea que cuatro de cada cinco jóvenes del colectivo LGTBI se sentirían más protegidos en un país islámico que en una España gobernada por Vox',\n",
              " 'crawled_date': '2024-04-20T03:15:56',\n",
              " 'country_of_origin': None,\n",
              " 'doc': '\"Cuatro de cada cinco jóvenes pertenecientes al colectivo LGTB reconocen que se sentirían más protegidos en un país islámico que en una España gobernada por Vox\". Este es el mensaje que se está difundiendo en Twitter (ahora X) como si lo hubiera publicado ABC. Es un bulo. La cuenta que lo publica no es la de ABC, sino @Santodebot, un perfil del que ya hemos desmentido otros contenidos y que en su biografía se define como \"parodia\".  Este es el contenido que se difunde:  Captura del bulo que se difunde.  La cuenta que lo publica no es la de ABC  El tuit se difunde como si lo hubiera publicado el diario ABC, con mensajes como estos: \"La propaganda ha calado bien hondo entonces\" o \"esto es producto del adoctrinamiento\".  Si nos fijamos en la cuenta vemos que tiene el nombre y la foto de perfil de ABC. Pero el handle (el nombre que va detrás de la arroba) es @Santodebot, mientras que el del diario es @abc_es.  Además, en su biografía añade que se trata de una cuenta \"parodia\". El perfil fue creado en mayo de 2019 y tiene algo más de 14.000 seguidores. En cambio, la cuenta de ABC se creó en 2009 y cuenta con más de dos millones de seguidores.  Cuenta del usuario @Santodebot y de ABC.  Además, no hay rastro de que ABC haya hecho esta supuesta publicación ni en su web ni a través de sus redes sociales.  En definitiva, es un bulo que ABC haya tuiteado que \"cuatro de cada cinco jóvenes\" del colectivo LGTBI \"se sentirían más protegidos en un país islámico que en una España gobernada por Vox\". La cuenta que lo difunde es @Santodebot, de la que ya hemos desmentido otros contenidos y que se autodefine como \"parodia\".',\n",
              " 'fact_source': 'maldita_es',\n",
              " 'factchecker': 'maldita.es',\n",
              " 'label': 'False',\n",
              " 'url': 'https://maldita.es/malditobulo/20240419/abc-jovenes-lgtbi-pais-islamico-vox/',\n",
              " 'lang': 'es',\n",
              " 'numerical': True,\n",
              " 'taxonomy_label': 'comparison'}"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_data[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FardkyUtyT2B",
        "outputId": "0900fe52-1942-4cdf-9787-59f90228dd40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "302"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(val_labels_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9xEVEmzpcSS",
        "outputId": "784f720d-4b1e-49e2-b9fa-bc1d706db66a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  [Claim]:Correos te pide 1,4€ por desinfectarte los paquetes[Evidences]: | 6 min lectura Nos habéis preguntado por otro mensaje relacionado con la marca española de automóviles SEAT y respiradores. En este habla un supuesto trabajador en nombre del empresa diciendo que la automovilística está esperando a que los hospitales españoles les pidan respiradores, y ofrecería un manual de instrucciones de los mismos. Adjunta además una dirección de correo electrónico y un teléfono. Este mensaje es falso. Así lo ha desmentido la compañía a Newtral.es. Ni han lanzado ninguna campaña similar, ni están teniendo problemas de distribución de los aparatos sanitarios. Una cadena de WhatsApp supuestamente proveniente de la Guardia Civil recomienda desinstalar la aplicación de videoconferencia Zoom, además de eliminar la cuenta. La cadena adjunta un tuit enviado por la cuenta oficial de la Guardia Civil. Sin embargo el tuit no dice eso, por tanto se trata de un mensaje falso. La pregunta a Dulceida en el Orgullo sacada de contexto La Guardia Civil tuiteó este 10 de abril que este mensaje de WhatsApp es un bulo “que aprovecha un tuit de la Guardia Civil y la actualización de seguridad de Zoom para usuarios de Windows para generar alarma social”. Es decir, que el tuit citado por la cadena no decía nada lo que contiene el texto. Circula por diferentes redes sociales un audio criticando al Gobierno en su gestión de la crisis sanitaria. El archivo va acompañado de un texto que asegura que el autor del mensaje grabado es el exministro socialista del Interior José Luis Corcuera. Ese dato es falso: se trata de un locutor de radio. Walter García Carro publicó un tuit reclamando la autoría del audio viral. En otro post de esta red social publicó un link a una plataforma en la que está colgado el programa entero al que pertenece el fragmento que tanto se ha viralizado. Desde fármacos hasta remedios caseros: los mitos sobre cómo evitar la resaca que contradicen la evidencia científica Nos preguntáis por una serie de mensajes que atribuyen al Gobierno la autoría y difusión de unas líneas temporales que mostrarían cuándo podrían ir reabriendo los comercios. Son falsas: no han salido del Gobierno. Un archivo compartido por WhatsApp llamado Fechas de apertura: (calendario tentativo que maneja el gobierno) es falsamente atribuido al Gobierno. Así nos lo han desmentido fuentes del propio organismo a Newtral.es. Circula un mensaje de Correos que solicita el pago de 1,40 euros para desinfectar tu paquete antes de recibirlo. Este mensaje es falso: se trata de phishing, una técnica para robar datos bancarios. Correos jamás pedirá pagos de ninguna cantidad a través de email o SMS. Siempre lo harán en la oficina o en el momento de la entrega. Circula por redes sociales un vídeo situado en Hungría según algunas versiones y en España según otras. También se dice que esas imágenes fueron grabadas durante los estados de alarma de los respectivos países por el coronavirus. ¿Qué hay de cierto en estos textos? Nada. El contexto que se le da estas imágenes es falso. En Bakú, capital de Azerbaiyán, se produjo el pasado 19 de octubre una manifestación contra la corrupción y en solicitud de unas elecciones libres. La policía azerí respondió con al menos 60 detenciones. De ahí es donde se sacaron las imágenes que se comparten como húngaras o españolas. Circula un mensaje por WhatsApp con pautas a seguir en caso de fallecimiento de un familiar por COVID-19. Mucha de la información que se da es errónea. Entre otras cosas, el mensaje asegura que la COVID-19 es una enfermedad profesional. El Real Decreto 1299/2006 recoge las consideradas enfermedades profesionales, y el coronavirus no se encuentra entre ellas. Circula un documento con un sello de la Guardia Civil con supuestos procedimientos que deben seguir algunos negocios, como el del taxi o el de la peluquería; o regulaciones tales como la prohibición del uso de espacios comunes entre vecinos. Este documento, sin embargo, es falso. Así lo ha desmentido la Guardia Civil en su cuenta oficial de Twitter, adjuntando un link al auténtico Real Decreto que establece qué actividades se pueden desarrollar y en qué condiciones. Recuerda que los pantallazos, fotografías y demás copias se pueden manipular. Si quieres conocer este tipo de informaciones, acude sola y directamente a fuentes oficiales. Un vídeo compartido más de mil veces en Facebook muestra a un hombre que se corta el cuello mientras huye de la policía. El título del vídeo lleva a pensar que ha sido grabado en España y afirma que es durante la cuarentena. Ambos datos son falsos: ni sucede en España, ni es actual. Varios medios serbios publicaron un suicidio de un hombre mientras huía de la policía serbia por la calle Alejandro I de Yugoslavia durante el pasado mes de enero, época durante la cual Serbia no había registrado casos de coronavirus ni estaba, mucho menos, en estado de alarma. Circula por WhatsApp una captura de pantalla de otro mensaje de la misma aplicación de mensajería que afirma que “a partir del lunes” la Junta de Extremadura permitirá salir a pasear por las avenidas. A continuación viene un link, el cual, al ser una captura de pantalla, no se puede pinchar. Al introducir la dirección en el navegador, vemos que es broma. Por tanto, el mensaje es falso. Pese a que el link del mensaje lleve a una imagen de un gorila, nos hemos puesto en contacto con la Junta, desde donde nos confirman que se trata de un bulo.\n",
            "Token IDs: tensor([    0, 10975, 45699, 42645, 15228,   241,   366,  3055,   181,  1949,\n",
            "          112,     6,   306, 10851,  2953,  2694, 37597, 13775,  3774,  6044,\n",
            "        15259,   293, 10975, 25377, 31688, 42645,  1721,   231,  5251, 25673,\n",
            "         3851, 29603,  2489,   428,  1140,   354,  1198,   571,  5973,  2102,\n",
            "         2953,  1021, 19937,   475,  1290,  1176,   242,  6258,  8647,  2102,\n",
            "         2764,   897,  4401,  3245,  2714,  6709,  6303,  3019,   263, 10948,\n",
            "         1479,   705,  4755,  6324,  2571,  1423, 44266,   625,  4765,     4,\n",
            "         2271,  8002,  2489,  3662,   102,   542, 28836,   257,   990,   139,\n",
            "         2664,   873,  1176,  9618,  1177,   295,  5223,   241,  2424,  2841,\n",
            "          642, 19716,   385, 13850, 12454,  1192,   897, 10948,  1417,   718,\n",
            "         1977,   620,  2426,  3304,  1526,  2714,  1741,  5502,    10,  1192,\n",
            "         3774,  1098,   293,  2714,  6709,  6303,  7003,  7427,   181, 34343,\n",
            "        44266,   625,  4765,     6,  1423,     9,   241,  7742,  5272,   542,\n",
            "        12769,   263,  9084,  2070,  7309,  1499,   293,   263,  3774, 21230,\n",
            "          366,     4,  1614,   267, 20339,  2329,   991,  6417,   542,   102,\n",
            "        10697, 12870,  2727,   263,  9240,   241,   139, 17995,  2727,  2684,\n",
            "         1423,   542, 19676,  1140,   506, 16405,     4,   381,  6526,   475,\n",
            "         1290,  1176,   242,  2714,   856, 19726,     4,   287,  1977,  4600,\n",
            "         2489,  2694,  1757,  6005,   897,  7753,   102,  6303,  5272,    10,\n",
            "        36997,  7085,     4,   293,     4, 11568,  1368,   260, 33532,   329,\n",
            "         2102,   295,   154,  4989,  2205,   102, 14379,  1122,     6, 10265,\n",
            "         3304,  7499,  2724,   118, 12454,   936,   281,   263,  7018,  8643,\n",
            "        20296,  2727,   263,  3774,    10,  5489, 29501, 15610,   405, 24198,\n",
            "            4,  1890,   102, 12260,  4242,   263,  6861, 28836,   257,   990,\n",
            "         5511,   242,  5401,  4843,   242,   263,   897,  6137,   493,  5280,\n",
            "         3872, 18832, 15205,  2694,   179,     2])\n"
          ]
        }
      ],
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in train_features:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', train_features[0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZavNUqipvVV",
        "outputId": "31c41f1b-0026-46f9-a8dc-3629b442a544"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  [Claim]:Acaba de salir un comunicado oficial de pepsi que no consuman 7up porque le echaron ácido muriático por error y ya van 8 muertos[Evidences]:“Acaba de salir un comunicado oficial de pepsi que no consuman 7up porque le echaron ácido muriático por error y ya van 8 muertos (sic)”, dice una imagen que circula en Facebook y Whatsapp. Pero es falso, se trata de desinformación que circula en internet al menos de 2017. A pesar de que la imagen contiene faltas de ortografía y verificadores de otros países lo desmintieron en años anteriores, usuarios de Facebook y WhatsApp compartieron recientemente la falsa alerta La empresa ya lo desmintió El 23 de septiembre de 2017, en la página oficial de Facebook del refresco 7Up se publicó un desmentido en donde narraba que el supuesto comunicado que recomendaba no consumir sus productos no era oficial y no había sido emitido por la empresa. Aprovecharon para destacar que siguen protocolos de seguridad en sus productos y que tienen estrictos controles de calidad. ¿De dónde salió esta desinformación? El 18 de septiembre de 2017, siete personas se intoxicaron tras presuntamente beber metanfetamina líquida de un refresco 7UP de dos litros en el estado de Baja California. Una de ellas murió. Animal Político informó en su momento que las autoridades de Baja California incautaron un lote de poco más de 400 mil refrescos de 2 litros 7Up en Valle de Mexicali, tras confirmarse la intoxicación. También levantaron una alerta sanitaria para evitar el consumo del producto. Pero en diciembre de ese mismo año, luego de destruir el lote contaminado y realizar las investigaciones pertinentes, levantaron la veda. Al respecto, 7Up hizo un pronunciamiento en donde señaló que colaboraría con las autoridades en la investigación. Sin embargo, con el paso de los años esta situación se fue sacando de contexto y se convirtió en desinformación que ya ha sido desmentida por verificadores de hechos de diferentes países como Maldito Bulo en España, Colombia Check en Colombia, y Es Paja en Venezuela. Por tanto, es falso que la empresa 7Up haya emitido un comunicado para alertar a la población sobre la presencia de ácido muriático en sus productos.\n",
            "Token IDs: tensor([    0, 10975, 45699, 42645, 26145,  6412,   263,  6641,   853,   542,\n",
            "         3137, 26488,  2102,     9, 23092,   263,   181,  2462, 11000,  1192,\n",
            "          117, 20411,   260,   262,   658,  2953,  3407,  2084,   364,   611,\n",
            "         9303,   952,  5543,   438,  6005, 22802,   118,  1526,    90,  2684,\n",
            "         2953,  5849,  1423, 13531,  3538,   290, 14701,  2399,   366, 10975,\n",
            "        25377, 31688, 42645,    17,    48, 26145,  6412,   263,  6641,   853,\n",
            "          542,  3137, 26488,  2102,     9, 23092,   263,   181,  2462, 11000,\n",
            "         1192,   117, 20411,   260,   262,   658,  2953,  3407,  2084,   364,\n",
            "          611,  9303,   952,  5543,   438,  6005, 22802,   118,  1526,    90,\n",
            "         2684,  2953,  5849,  1423, 13531,  3538,   290, 14701,  2399,   366,\n",
            "           36, 15335,    43,    17,    46,     6, 23819,   542,   102, 26031,\n",
            "          225,  1192, 27884,  5571,  1177,   622,  1423, 35415,  3340,     4,\n",
            "         2595,   139,  2714,   856, 19726,     6,   842,  2664,  2186,   263,\n",
            "         2694,   179,  3899,  5014,  2727,  1192, 27884,  5571,  1177,  2888,\n",
            "         1076,   604,   366,   263,   193,     4,    83,   181, 19115,   263,\n",
            "         1192,   897, 26031,   225,  8541,   118,  2552,   856,  3967,   281,\n",
            "          263,    50,    90,  2154, 13883,  5272,  1423,  4342,  8685,   625,\n",
            "         4765,   263, 19313,  3985,  6044,  1977, 24151,  4600,  2694, 30732,\n",
            "          906,   261,  1177,    10,  6303,   366,    41,  1334,   118,  4765,\n",
            "            6,   201,   257, 24198,   263,   622,  1423,  6861,  7753,  2013,\n",
            "          906,   261,  3872,  4843,  6285,   242,   897, 22461,   102,  5439,\n",
            "          102,  1587,  2841,   642, 19716, 13531,  4600,  2694, 30732,   118,\n",
            "         1479,  1448,   883,   263,   842,  3320,  9173,  7805,   263,   193,\n",
            "            6,  1177,   897,   181,  1526,   571,  1243,     9, 23092,   263,\n",
            "          622,  2424, 39240,   876,   262, 10926,   842,   285,  1479,   542,\n",
            "         2694,  1757,  6005,  1177,   385,     2])\n"
          ]
        }
      ],
      "source": [
        "val_input_ids = []\n",
        "val_attention_masks = []\n",
        "\n",
        "for sent in val_features:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    val_input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    val_attention_masks.append(encoded_dict['attention_mask'])\n",
        "# Convert the lists into tensors.\n",
        "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
        "val_attention_masks = torch.cat(val_attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', val_features[0])\n",
        "print('Token IDs:', val_input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "evSioYADp_y4"
      },
      "outputs": [],
      "source": [
        "train_labels_final = torch.tensor(train_labels_final)\n",
        "val_labels_final = torch.tensor(val_labels_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Nk-HGh0yWwf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC7Tt92syW5Z",
        "outputId": "64a194d8-1181-42e3-ba59-8c9c98f2bf43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([302])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_labels_final.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLCxP_iqzspd",
        "outputId": "087ff474-3216-4443-94f5-f715b629e453"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "302"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(val_input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIo3GxyUrMml",
        "outputId": "2c75132b-6972-4fe2-90a0-6f2c4c54452f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['True', 'False', 'Conflicting']"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_classes = len(list(set(train_labels)))\n",
        "list(set(train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg90AQJcrZFD",
        "outputId": "4cba898f-d42c-41e7-85b5-66c8134a90ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPp5pBNjp35w",
        "outputId": "4d964737-d0a4-4b71-cd04-9ac07f455b4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Conflicting', 'False', 'True'], dtype='<U11')"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LE.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "KOK3P-9Gra78"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "# train_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n",
        "# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, train_labels_final)\n",
        "val_dataset = TensorDataset(val_input_ids, val_attention_masks,val_labels_final)\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "c6ALqnRkrjBN"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(\n",
        "            dataset,  # The training samples.\n",
        "            sampler = RandomSampler(dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "cKSZPwobrl8y"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "class MultiClassClassifier(nn.Module):\n",
        "    def __init__(self, bert_model_path, labels_count, hidden_dim=768, mlp_dim=500, extras_dim=100, dropout=0.1, freeze_bert=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.roberta = AutoModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, mlp_dim),\n",
        "            nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # # nn.ReLU(),\n",
        "            # # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),\n",
        "            nn.Linear(mlp_dim, labels_count)\n",
        "        )\n",
        "        # self.softmax = nn.LogSoftmax(dim=1)\n",
        "        if freeze_bert:\n",
        "            print(\"Freezing layers\")\n",
        "            for param in self.roberta.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, tokens, masks):\n",
        "        output = self.roberta(tokens, attention_mask=masks)\n",
        "        dropout_output = self.dropout(output[\"pooler_output\"])\n",
        "        # concat_output = torch.cat((dropout_output, topic_emb), dim=1)\n",
        "        # concat_output = self.dropout(concat_output)\n",
        "        mlp_output = self.mlp(dropout_output)\n",
        "        # proba = self.sigmoid(mlp_output)\n",
        "        # proba = self.softmax(mlp_output)\n",
        "\n",
        "        return mlp_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986,
          "referenced_widgets": [
            "c85dfe45916e4fd2bde577671b638545",
            "321b8c67ad514136973fa165ce1fa150",
            "93f6560dfb294ff3aa70ebdcebb68af5",
            "674626d7375845969566ab5924291510",
            "62372fc3b77d403fa1c7a951ac131486",
            "48eedc54a44f4ad0803790deca8eb1f0",
            "30765132cd1d497abb5819c90305349d",
            "0c2fa22b85374f90949a169019ee7149",
            "e63832ecd9464780905b4ee6d9cbbd3e",
            "a9eea694c39246a0943885aa1f8c1938",
            "6f1eddf15edf4496b5d90c0f5561758d",
            "ad956be746844fbaa439f5d324e609cb",
            "98afaf1a35bb4aa9be426b04a0540bd0",
            "c471c289770646de98644d2f6d8135c9",
            "83b6b0f56c5d4014a45ef9b63ec38a68",
            "2c5678d9091e428c82ba59aca17d2167",
            "9735ffcc84a5419bb48d7ea20c39de97",
            "f54200478abe490d9e9d569e72382b3a",
            "e13bfcc99d5d47a9842587576f2c8288",
            "a8ecd943344245698fd5e16d61dc45be",
            "390ecd5a1d2343ae89e3012fe8385be7",
            "4c5c165e9c354856aa268f17b8991969"
          ]
        },
        "id": "CAxysrcNsFl8",
        "outputId": "00ec8910-34dd-4aa6-b336-5d9b6bdc2ed9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at uf-aice-lab/math-roberta and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MultiClassClassifier(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (mlp): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=768, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Loads BertForSequenceClassification, the pretrained BERT model with a single\n",
        "model = MultiClassClassifier(\"uf-aice-lab/math-roberta\",num_classes, 1024,768,140,dropout=0.1,freeze_bert=False)\n",
        "\n",
        "# model.load_state_dict(torch.load(\"model_bert_difficulty_prediction/model_weights\"))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBtbVgt4QwIh"
      },
      "outputs": [],
      "source": [
        "# model.load_state_dict(torch.load(\"model_bert_difficulty_prediction/model_weights\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iilNEZRCsJjH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awQ2Y9Jb3kht",
        "outputId": "c8895c2c-a9a2-43ec-9bf7-8d09821ce216"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "2Ys-M4-e3khv"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrYqErOD3khx",
        "outputId": "3af1a631-221c-46fb-fb09-b940f3b61509"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWVSE9LM3kh0",
        "outputId": "4f0501f5-0346-47ec-e80a-d59ea67b69b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "61920"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "1935 * 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "rcvxVVi63kh3"
      },
      "outputs": [],
      "source": [
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "GUw3zm6g3kh5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "ta6zfUTa3kh7"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "GFq9gd5kQSHb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "a_nmuoSgQ5t3"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "ugVDrHu20c8G"
      },
      "outputs": [],
      "source": [
        "for param in model.roberta.encoder.layer[0:5].parameters():\n",
        "    param.requires_grad=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "E1rDO58zMfc8"
      },
      "outputs": [],
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LhAy2hZ3kh9",
        "outputId": "4fb6e10c-af5f-4a21-df61-6acd8ea29dc1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "RobertaSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: out of memory\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[104], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Perform a forward pass (evaluate the model on this training batch).\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m probas \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb_input_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Accumulate the training loss over all of the batches so that we can\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# calculate the average loss at the end. `loss` is a Tensor containing a\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# single value; the `.item()` function just returns the Python value\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# from the tensor.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(probas, b_labels)\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[91], line 24\u001b[0m, in \u001b[0;36mMultiClassClassifier.forward\u001b[1;34m(self, tokens, masks)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens, masks):\n\u001b[1;32m---> 24\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     dropout_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpooler_output\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# concat_output = torch.cat((dropout_output, topic_emb), dim=1)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# concat_output = self.dropout(concat_output)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:976\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    974\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 976\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    989\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:631\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    620\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    621\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    622\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    628\u001b[0m         output_attentions,\n\u001b[0;32m    629\u001b[0m     )\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 631\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:520\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    510\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    517\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    519\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 520\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:447\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    439\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    446\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 447\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    456\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    457\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:313\u001b[0m, in \u001b[0;36mRobertaSdpaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m output_attentions \u001b[38;5;129;01mor\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;66;03m# TODO: Improve this warning with e.g. `model.config._attn_implementation = \"manual\"` once implemented.\u001b[39;00m\n\u001b[0;32m    306\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`attn_implementation=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m` when loading the model.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    312\u001b[0m     )\n\u001b[1;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m bsz, tgt_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m    325\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery(hidden_states))\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:267\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    263\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# Mask heads if we want to\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1426\u001b[0m )\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss,\n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "early_stopping = EarlyStopping(patience=2, verbose=True)\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_accuracy = 0\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to\n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questimport gensim.downloader as api\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        # b_poincare = batch[2].to(device)\n",
        "        # b_difficulty = batch[3].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        # skill_labels = batch[3].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because\n",
        "        # accumulating the gradients is \"convenient while training RNNs\".\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        probas = model(b_input_ids,b_input_mask)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value\n",
        "        # from the tensor.\n",
        "        loss = loss_func(probas, b_labels)\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        # scheduler.step()\n",
        "        logits = probas.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        total_train_accuracy += flat_accuracy(logits, label_ids)\n",
        "    avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n",
        "    print(\" Train Accuracy: {0:.2f}\".format(avg_train_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        # b_poincare = batch[2].to(device)\n",
        "        # b_difficulty = batch[3].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        # skill_labels = batch[3].to(device)\n",
        "\n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "\n",
        "          logits = model(b_input_ids,b_input_mask)\n",
        "\n",
        "        # Accumulate the validation loss.\n",
        "        loss = loss_func(logits, b_labels)\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    early_stopping(avg_val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "      print(\"Early stopping\")\n",
        "      break\n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    output_dir = 'math_roberta_claimdecomp_final_continued/'\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    print(\"Saving model to %s\" % output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n",
        "\n",
        "    !rm -rf \"/content/drive/My Drive/ecir_compnumfacts/math_roberta_claimdecomp_final_continued\"\n",
        "    !mv math_roberta_claimdecomp_final_continued \"/content/drive/My Drive/ecir_compnumfacts/\"\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEdbFmsN2kAz"
      },
      "outputs": [],
      "source": [
        "tokenizer.save_pretrained(\"math_roberta_claimdecomp_final_continued_1\")\n",
        "torch.save(model.state_dict(), os.path.join(\"math_roberta_claimdecomp_final_continued_1\", 'model_weights'))\n",
        "\n",
        "!rm -rf \"/content/drive/My Drive/ecir_compnumfacts/math_roberta_claimdecomp_final_continued_1\"\n",
        "!mv math_roberta_claimdecomp_final_continued_1 \"/content/drive/My Drive/ecir_compnumfacts/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzLQ6lNltGX7"
      },
      "outputs": [],
      "source": [
        "LE.inverse_transform([0,1,2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEEKmPey0a8-"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from huggingface_hub import login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFR-s_8ZtATC"
      },
      "outputs": [],
      "source": [
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWkkt0F4Ifwc"
      },
      "outputs": [],
      "source": [
        "LE.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xy__BpY8VOQp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "clef",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "005aecb9af7446aab0512347fc4faf1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "057f6824b04047b9a64bd33c13374fdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0636f2033560480bb67985b0128a6174": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "069fac70741e46aa8455c3c68e286148": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a407fbab91d416dad54911ca5ae34f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c2fa22b85374f90949a169019ee7149": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ccf64e07be7473bad93cef52cd9d39c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d7f346bdfd1408fa34dbc0dd383a2e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7423e1a60ba34753bb14954981e6f62b",
            "placeholder": "​",
            "style": "IPY_MODEL_df59719e8bf44e1bb349f98674efefa6",
            "value": "merges.txt: 100%"
          }
        },
        "0f55c98cc4b14bbb86e5d7eecef4dd65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_005aecb9af7446aab0512347fc4faf1e",
            "placeholder": "​",
            "style": "IPY_MODEL_ca4b25ceac5c4b6c813ac9fa59b2ddce",
            "value": "tokenizer.json: 100%"
          }
        },
        "1925cff7d7544e069040f271537df7a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1db03cf091254bb6bab2c88f76916146": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "222e80b8c42d481da3a75a24960e74ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27d070e0bc0f43afb42d9f18f0b13b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1db03cf091254bb6bab2c88f76916146",
            "placeholder": "​",
            "style": "IPY_MODEL_222e80b8c42d481da3a75a24960e74ad",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 15.5MB/s]"
          }
        },
        "2c5678d9091e428c82ba59aca17d2167": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dd91549d6fc42d5a5bea3df78df29be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30765132cd1d497abb5819c90305349d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31ade0d811df4904b4de6a75a9eb3898": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7f67153d4104250a073b6f5eca34007",
              "IPY_MODEL_59620c8d958f4e2482fb8c5cf679a3b7",
              "IPY_MODEL_6e1218c6af9c4fec8c43fbcbd0d7b961"
            ],
            "layout": "IPY_MODEL_9673bee129574b1db39a8bf6dfa79be1"
          }
        },
        "321b8c67ad514136973fa165ce1fa150": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48eedc54a44f4ad0803790deca8eb1f0",
            "placeholder": "​",
            "style": "IPY_MODEL_30765132cd1d497abb5819c90305349d",
            "value": "config.json: 100%"
          }
        },
        "390ecd5a1d2343ae89e3012fe8385be7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ceb6758d9634a1197376d4e27f5e615": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e64febdc47d48ef9a185fcb5e4ce81e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_457c1f1c50aa42c3b01e9d50fdd0ec8f",
            "placeholder": "​",
            "style": "IPY_MODEL_ce09d6c4222640148d668939bab5008e",
            "value": " 456k/456k [00:00&lt;00:00, 9.54MB/s]"
          }
        },
        "41ad5d582748475e934bd6d7bbc6db88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dd91549d6fc42d5a5bea3df78df29be",
            "placeholder": "​",
            "style": "IPY_MODEL_e962acc9f7944bd6a14a899d27e5825c",
            "value": " 899k/899k [00:00&lt;00:00, 13.6MB/s]"
          }
        },
        "4272c15544ac483f99cfeb9c2046e2fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43cb251e9222448a900f03c42e58592d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "457c1f1c50aa42c3b01e9d50fdd0ec8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "483ad42b17b8441880d908d711e0c3b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f55c98cc4b14bbb86e5d7eecef4dd65",
              "IPY_MODEL_ad6ac6b0974e4699996289653def8861",
              "IPY_MODEL_27d070e0bc0f43afb42d9f18f0b13b6e"
            ],
            "layout": "IPY_MODEL_fcadec008dc54e6583a800b746d7a001"
          }
        },
        "48eedc54a44f4ad0803790deca8eb1f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bdc157bf7b3479b918cb087c4804bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c5c165e9c354856aa268f17b8991969": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59620c8d958f4e2482fb8c5cf679a3b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ccf64e07be7473bad93cef52cd9d39c",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ceb6758d9634a1197376d4e27f5e615",
            "value": 482
          }
        },
        "614599e3e614429ab0b97c69081a0e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "62372fc3b77d403fa1c7a951ac131486": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "674626d7375845969566ab5924291510": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9eea694c39246a0943885aa1f8c1938",
            "placeholder": "​",
            "style": "IPY_MODEL_6f1eddf15edf4496b5d90c0f5561758d",
            "value": " 673/673 [00:00&lt;00:00, 28.7kB/s]"
          }
        },
        "678d8a2512484175b923785849fbd605": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a6eba5085eb4de0939d33d7b9140612": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e1218c6af9c4fec8c43fbcbd0d7b961": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_678d8a2512484175b923785849fbd605",
            "placeholder": "​",
            "style": "IPY_MODEL_4272c15544ac483f99cfeb9c2046e2fa",
            "value": " 482/482 [00:00&lt;00:00, 32.4kB/s]"
          }
        },
        "6f1eddf15edf4496b5d90c0f5561758d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70b7cd65577f4afaaac2dc9b5ae121c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7423e1a60ba34753bb14954981e6f62b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ca9f4424bae4460a9850d4f6ff4da18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7eb5d9cacc6c41a58994a1615a44d086": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c78a28c25acc4f9b87392719681101cd",
              "IPY_MODEL_9b51530a76f94da4ae27a7f25cf27ee3",
              "IPY_MODEL_d1ef085b43794d1bb4f92acbd5f6f634",
              "IPY_MODEL_fa555a2e0115487599c31d2368b83fff",
              "IPY_MODEL_e379ef253a774d6e8125ee20495813f4"
            ],
            "layout": "IPY_MODEL_91c3323870d64d82b858dd723baeba89"
          }
        },
        "83b6b0f56c5d4014a45ef9b63ec38a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_390ecd5a1d2343ae89e3012fe8385be7",
            "placeholder": "​",
            "style": "IPY_MODEL_4c5c165e9c354856aa268f17b8991969",
            "value": " 1.42G/1.42G [00:08&lt;00:00, 252MB/s]"
          }
        },
        "8955b698cf2340e58d523a6f03e0026c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a73d2714c1342b1ab1185a74fef6198": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91c3323870d64d82b858dd723baeba89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "93f6560dfb294ff3aa70ebdcebb68af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c2fa22b85374f90949a169019ee7149",
            "max": 673,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e63832ecd9464780905b4ee6d9cbbd3e",
            "value": 673
          }
        },
        "9673bee129574b1db39a8bf6dfa79be1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9735ffcc84a5419bb48d7ea20c39de97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98afaf1a35bb4aa9be426b04a0540bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9735ffcc84a5419bb48d7ea20c39de97",
            "placeholder": "​",
            "style": "IPY_MODEL_f54200478abe490d9e9d569e72382b3a",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "9b51530a76f94da4ae27a7f25cf27ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_a8203576ad384b88895f72ee923c5ca7",
            "placeholder": "​",
            "style": "IPY_MODEL_7ca9f4424bae4460a9850d4f6ff4da18",
            "value": ""
          }
        },
        "a356d976c5bc437aba9ef1964dffbccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a63bab1fbb7f47c08404c2c8e576c8ab",
              "IPY_MODEL_e1c27f82724d40179ecb939f1bcf3e19",
              "IPY_MODEL_41ad5d582748475e934bd6d7bbc6db88"
            ],
            "layout": "IPY_MODEL_057f6824b04047b9a64bd33c13374fdc"
          }
        },
        "a5ff5c0f2e07418aace9422001961472": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db1d477460f14fce85dc2b9c3bb089e3",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9c03217bf794c309381666a45b26804",
            "value": 456318
          }
        },
        "a63bab1fbb7f47c08404c2c8e576c8ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a407fbab91d416dad54911ca5ae34f2",
            "placeholder": "​",
            "style": "IPY_MODEL_6a6eba5085eb4de0939d33d7b9140612",
            "value": "vocab.json: 100%"
          }
        },
        "a8203576ad384b88895f72ee923c5ca7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8ecd943344245698fd5e16d61dc45be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9eea694c39246a0943885aa1f8c1938": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab72101a46d64a199383b4855ba969a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d7f346bdfd1408fa34dbc0dd383a2e9",
              "IPY_MODEL_a5ff5c0f2e07418aace9422001961472",
              "IPY_MODEL_3e64febdc47d48ef9a185fcb5e4ce81e"
            ],
            "layout": "IPY_MODEL_0636f2033560480bb67985b0128a6174"
          }
        },
        "ad6ac6b0974e4699996289653def8861": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1925cff7d7544e069040f271537df7a8",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a73d2714c1342b1ab1185a74fef6198",
            "value": 1355863
          }
        },
        "ad956be746844fbaa439f5d324e609cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98afaf1a35bb4aa9be426b04a0540bd0",
              "IPY_MODEL_c471c289770646de98644d2f6d8135c9",
              "IPY_MODEL_83b6b0f56c5d4014a45ef9b63ec38a68"
            ],
            "layout": "IPY_MODEL_2c5678d9091e428c82ba59aca17d2167"
          }
        },
        "be2b1c33c0d54cd2a2e39cf52ec70957": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4563c6693d943f0923dd1db90609bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c471c289770646de98644d2f6d8135c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e13bfcc99d5d47a9842587576f2c8288",
            "max": 1421785643,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8ecd943344245698fd5e16d61dc45be",
            "value": 1421785643
          }
        },
        "c78a28c25acc4f9b87392719681101cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8955b698cf2340e58d523a6f03e0026c",
            "placeholder": "​",
            "style": "IPY_MODEL_e31fd0b45a8546e0be873fc56d35959f",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "c85dfe45916e4fd2bde577671b638545": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_321b8c67ad514136973fa165ce1fa150",
              "IPY_MODEL_93f6560dfb294ff3aa70ebdcebb68af5",
              "IPY_MODEL_674626d7375845969566ab5924291510"
            ],
            "layout": "IPY_MODEL_62372fc3b77d403fa1c7a951ac131486"
          }
        },
        "ca4b25ceac5c4b6c813ac9fa59b2ddce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce09d6c4222640148d668939bab5008e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1ef085b43794d1bb4f92acbd5f6f634": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_d849148804c747c8aba9cbda38accd67",
            "style": "IPY_MODEL_be2b1c33c0d54cd2a2e39cf52ec70957",
            "value": true
          }
        },
        "d7f67153d4104250a073b6f5eca34007": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8158a7b594e42b29a18c54aefd2c045",
            "placeholder": "​",
            "style": "IPY_MODEL_70b7cd65577f4afaaac2dc9b5ae121c7",
            "value": "config.json: 100%"
          }
        },
        "d849148804c747c8aba9cbda38accd67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db1d477460f14fce85dc2b9c3bb089e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df59719e8bf44e1bb349f98674efefa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e13bfcc99d5d47a9842587576f2c8288": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1c27f82724d40179ecb939f1bcf3e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4563c6693d943f0923dd1db90609bfb",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_069fac70741e46aa8455c3c68e286148",
            "value": 898823
          }
        },
        "e31fd0b45a8546e0be873fc56d35959f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e379ef253a774d6e8125ee20495813f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffd4ff391ded454299848594a048f6c7",
            "placeholder": "​",
            "style": "IPY_MODEL_43cb251e9222448a900f03c42e58592d",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "e63832ecd9464780905b4ee6d9cbbd3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8158a7b594e42b29a18c54aefd2c045": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e962acc9f7944bd6a14a899d27e5825c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9c03217bf794c309381666a45b26804": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f54200478abe490d9e9d569e72382b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa555a2e0115487599c31d2368b83fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_4bdc157bf7b3479b918cb087c4804bdc",
            "style": "IPY_MODEL_614599e3e614429ab0b97c69081a0e18",
            "tooltip": ""
          }
        },
        "fcadec008dc54e6583a800b746d7a001": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffd4ff391ded454299848594a048f6c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
