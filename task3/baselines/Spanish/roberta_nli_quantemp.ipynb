{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## es para generar un clasificador como baseline. El problema es que en ingles utiliza la pregunta\n",
        "## se debe entrenar para espaÃ±ol sin utilizar la pregunta, solo doc + claim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egtdWTvcOeTy",
        "outputId": "731ee16b-c89f-4ddd-a65b-1f2a9b140fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AlOzas-OzjA",
        "outputId": "15904d10-17d5-4e0d-c893-ef7dba02fe33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.51.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\edu\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (3.4.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.3; however, version 25.1.1 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\Edu\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQgFwRXu0_U6",
        "outputId": "b205b974-6854-40df-f5f6-7b66151994da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.30.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (2024.12.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: requests in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface_hub) (3.0.12)\n",
            "Requirement already satisfied: colorama in c:\\users\\edu\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface_hub) (2019.11.28)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface_hub) (2.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\edu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface_hub) (2.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.3; however, version 25.1.1 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\Edu\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub\n",
        "from huggingface_hub import notebook_login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331,
          "referenced_widgets": [
            "7eb5d9cacc6c41a58994a1615a44d086",
            "c78a28c25acc4f9b87392719681101cd",
            "9b51530a76f94da4ae27a7f25cf27ee3",
            "d1ef085b43794d1bb4f92acbd5f6f634",
            "fa555a2e0115487599c31d2368b83fff",
            "e379ef253a774d6e8125ee20495813f4",
            "91c3323870d64d82b858dd723baeba89",
            "8955b698cf2340e58d523a6f03e0026c",
            "e31fd0b45a8546e0be873fc56d35959f",
            "a8203576ad384b88895f72ee923c5ca7",
            "7ca9f4424bae4460a9850d4f6ff4da18",
            "d849148804c747c8aba9cbda38accd67",
            "be2b1c33c0d54cd2a2e39cf52ec70957",
            "4bdc157bf7b3479b918cb087c4804bdc",
            "614599e3e614429ab0b97c69081a0e18",
            "ffd4ff391ded454299848594a048f6c7",
            "43cb251e9222448a900f03c42e58592d"
          ]
        },
        "id": "ayFV2esI1DsP",
        "outputId": "c614d229-cf0c-4acd-f9eb-293889806218"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f3a6d98e24b4c19a4d12f76000a723e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "notebook_login()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "a356d976c5bc437aba9ef1964dffbccb",
            "a63bab1fbb7f47c08404c2c8e576c8ab",
            "e1c27f82724d40179ecb939f1bcf3e19",
            "41ad5d582748475e934bd6d7bbc6db88",
            "057f6824b04047b9a64bd33c13374fdc",
            "0a407fbab91d416dad54911ca5ae34f2",
            "6a6eba5085eb4de0939d33d7b9140612",
            "c4563c6693d943f0923dd1db90609bfb",
            "069fac70741e46aa8455c3c68e286148",
            "2dd91549d6fc42d5a5bea3df78df29be",
            "e962acc9f7944bd6a14a899d27e5825c",
            "ab72101a46d64a199383b4855ba969a6",
            "0d7f346bdfd1408fa34dbc0dd383a2e9",
            "a5ff5c0f2e07418aace9422001961472",
            "3e64febdc47d48ef9a185fcb5e4ce81e",
            "0636f2033560480bb67985b0128a6174",
            "7423e1a60ba34753bb14954981e6f62b",
            "df59719e8bf44e1bb349f98674efefa6",
            "db1d477460f14fce85dc2b9c3bb089e3",
            "e9c03217bf794c309381666a45b26804",
            "457c1f1c50aa42c3b01e9d50fdd0ec8f",
            "ce09d6c4222640148d668939bab5008e",
            "483ad42b17b8441880d908d711e0c3b5",
            "0f55c98cc4b14bbb86e5d7eecef4dd65",
            "ad6ac6b0974e4699996289653def8861",
            "27d070e0bc0f43afb42d9f18f0b13b6e",
            "fcadec008dc54e6583a800b746d7a001",
            "005aecb9af7446aab0512347fc4faf1e",
            "ca4b25ceac5c4b6c813ac9fa59b2ddce",
            "1925cff7d7544e069040f271537df7a8",
            "8a73d2714c1342b1ab1185a74fef6198",
            "1db03cf091254bb6bab2c88f76916146",
            "222e80b8c42d481da3a75a24960e74ad",
            "31ade0d811df4904b4de6a75a9eb3898",
            "d7f67153d4104250a073b6f5eca34007",
            "59620c8d958f4e2482fb8c5cf679a3b7",
            "6e1218c6af9c4fec8c43fbcbd0d7b961",
            "9673bee129574b1db39a8bf6dfa79be1",
            "e8158a7b594e42b29a18c54aefd2c045",
            "70b7cd65577f4afaaac2dc9b5ae121c7",
            "0ccf64e07be7473bad93cef52cd9d39c",
            "3ceb6758d9634a1197376d4e27f5e615",
            "678d8a2512484175b923785849fbd605",
            "4272c15544ac483f99cfeb9c2046e2fa"
          ]
        },
        "id": "C_-uxEt3O1Y_",
        "outputId": "38e9a0a3-c4e5-489b-e3b8-b9bb5f3aa044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading roBERT tokenizer...\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer,AutoModel, RobertaTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading roBERT tokenizer...')\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A84PEHj6k13e",
        "outputId": "bf33bdb3-9d14-47cf-e8a7-623b7b9d66d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1506"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json #English/test_set_english_claim.json\n",
        "with open(\"../../data/Spanish/train_spanish_claims.json\", encoding='utf-8') as f:\n",
        "  data = json.load(f)\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "#data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 1204\n",
            "Test size: 302\n"
          ]
        }
      ],
      "source": [
        "# split test_data \n",
        "# Calculate split index\n",
        "split_index = int(0.8 * len(data))\n",
        "\n",
        "# Split the data\n",
        "train_data = data[:split_index]\n",
        "val_data = data[split_index:]\n",
        "print(f\"Train size: {len(train_data)}\")\n",
        "print(f\"Test size: {len(val_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'claim': 'Correos te pide 1,4â¬ por desinfectarte los paquetes',\n",
              " 'crawled_date': '2020-04-25',\n",
              " 'country_of_origin': 'spain',\n",
              " 'doc': ' | 6 min lectura Nos habÃ©is preguntado por otro mensaje relacionado con la marca espaÃ±ola de automÃ³viles SEAT y respiradores. En este habla un supuesto trabajador en nombre del empresa diciendo que la automovilÃ­stica estÃ¡ esperando a que los hospitales espaÃ±oles les pidan respiradores, y ofrecerÃ­a un manual de instrucciones de los mismos. Adjunta ademÃ¡s una direcciÃ³n de correo electrÃ³nico y un telÃ©fono. Este mensaje es falso. AsÃ­ lo ha desmentido la compaÃ±Ã­a a Newtral.es. Ni han lanzado ninguna campaÃ±a similar, ni estÃ¡n teniendo problemas de distribuciÃ³n de los aparatos sanitarios. Una cadena de WhatsApp supuestamente proveniente de la Guardia Civil recomienda desinstalar la aplicaciÃ³n de videoconferencia Zoom, ademÃ¡s de eliminar la cuenta. La cadena adjunta un tuit enviado por la cuenta oficial de la Guardia Civil. Sin embargo el tuit no dice eso, por tanto se trata de un mensaje falso. La pregunta a Dulceida en el Orgullo sacada de contexto La Guardia Civil tuiteÃ³ este 10 de abril que este mensaje de WhatsApp es un bulo âque aprovecha un tuit de la Guardia Civil y la actualizaciÃ³n de seguridad de Zoom para usuarios de Windows para generar alarma socialâ. Es decir, que el tuit citado por la cadena no decÃ­a nada lo que contiene el texto. Circula por diferentes redes sociales un audio criticando al Gobierno en su gestiÃ³n de la crisis sanitaria. El archivo va acompaÃ±ado de un texto que asegura que el autor del mensaje grabado es el exministro socialista del Interior JosÃ© Luis Corcuera. Ese dato es falso: se trata de un locutor de radio. Walter GarcÃ­a Carro publicÃ³ un tuit reclamando la autorÃ­a del audio viral. En otro post de esta red social publicÃ³ un link a una plataforma en la que estÃ¡ colgado el programa entero al que pertenece el fragmento que tanto se ha viralizado. Desde fÃ¡rmacos hasta remedios caseros: los mitos sobre cÃ³mo evitar la resaca que contradicen la evidencia cientÃ­fica Nos preguntÃ¡is por una serie de mensajes que atribuyen al Gobierno la autorÃ­a y difusiÃ³n de unas lÃ­neas temporales que mostrarÃ­an cuÃ¡ndo podrÃ­an ir reabriendo los comercios. Son falsas: no han salido del Gobierno. Un archivo compartido por WhatsApp llamado Fechas de apertura: (calendario tentativo que maneja el gobierno) es falsamente atribuido al Gobierno. AsÃ­ nos lo han desmentido fuentes del propio organismo a Newtral.es. Circula un mensaje de Correos que solicita el pago de 1,40 euros para desinfectar tu paquete antes de recibirlo. Este mensaje es falso: se trata de phishing, una tÃ©cnica para robar datos bancarios. Correos jamÃ¡s pedirÃ¡ pagos de ninguna cantidad a travÃ©s de email o SMS. Siempre lo harÃ¡n en la oficina o en el momento de la entrega. Circula por redes sociales un vÃ­deo situado en HungrÃ­a segÃºn algunas versiones y en EspaÃ±a segÃºn otras. TambiÃ©n se dice que esas imÃ¡genes fueron grabadas durante los estados de alarma de los respectivos paÃ­ses por el coronavirus. Â¿QuÃ© hay de cierto en estos textos? Nada. El contexto que se le da estas imÃ¡genes es falso. En BakÃº, capital de AzerbaiyÃ¡n, se produjo el pasado 19 de octubre una manifestaciÃ³n contra la corrupciÃ³n y en solicitud de unas elecciones libres. La policÃ­a azerÃ­ respondiÃ³ con al menos 60 detenciones. De ahÃ­ es donde se sacaron las imÃ¡genes que se comparten como hÃºngaras o espaÃ±olas. Circula un mensaje por WhatsApp con pautas a seguir en caso de fallecimiento de un familiar por COVID-19. Mucha de la informaciÃ³n que se da es errÃ³nea. Entre otras cosas, el mensaje asegura que la COVID-19 es una enfermedad profesional. El Real Decreto 1299/2006 recoge las consideradas enfermedades profesionales, y el coronavirus no se encuentra entre ellas. Circula un documento con un sello de la Guardia Civil con supuestos procedimientos que deben seguir algunos negocios, como el del taxi o el de la peluquerÃ­a; o regulaciones tales como la prohibiciÃ³n del uso de espacios comunes entre vecinos. Este documento, sin embargo, es falso. AsÃ­ lo ha desmentido la Guardia Civil en su cuenta oficial de Twitter, adjuntando un link al autÃ©ntico Real Decreto que establece quÃ© actividades se pueden desarrollar y en quÃ© condiciones. Recuerda que los pantallazos, fotografÃ­as y demÃ¡s copias se pueden manipular. Si quieres conocer este tipo de informaciones, acude sola y directamente a fuentes oficiales. Un vÃ­deo compartido mÃ¡s de mil veces en Facebook muestra a un hombre que se corta el cuello mientras huye de la policÃ­a. El tÃ­tulo del vÃ­deo lleva a pensar que ha sido grabado en EspaÃ±a y afirma que es durante la cuarentena. Ambos datos son falsos: ni sucede en EspaÃ±a, ni es actual. Varios medios serbios publicaron un suicidio de un hombre mientras huÃ­a de la policÃ­a serbia por la calle Alejandro I de Yugoslavia durante el pasado mes de enero, Ã©poca durante la cual Serbia no habÃ­a registrado casos de coronavirus ni estaba, mucho menos, en estado de alarma. Circula por WhatsApp una captura de pantalla de otro mensaje de la misma aplicaciÃ³n de mensajerÃ­a que afirma que âa partir del lunesâ la Junta de Extremadura permitirÃ¡ salir a pasear por las avenidas. A continuaciÃ³n viene un link, el cual, al ser una captura de pantalla, no se puede pinchar. Al introducir la direcciÃ³n en el navegador, vemos que es broma. Por tanto, el mensaje es falso. Pese a que el link del mensaje lleve a una imagen de un gorila, nos hemos puesto en contacto con la Junta, desde donde nos confirman que se trata de un bulo.',\n",
              " 'fact_source': 'newtral',\n",
              " 'factchecker': ['Por Newtral'],\n",
              " 'label': 'False',\n",
              " 'url': 'https://www.newtral.es/covid-19-epidemia-mundial-de-bulos-2/20200425/',\n",
              " 'lang': 'es',\n",
              " 'numerical': True,\n",
              " 'taxonomy_label': 'statistical'}"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "A96MxV43kwaS"
      },
      "outputs": [],
      "source": [
        "val_claims = []\n",
        "for fact in val_data:\n",
        "        strencode = fact[\"claim\"].encode(\"ascii\", \"ignore\")\n",
        "        strdecode = strencode.decode()\n",
        "        val_claims.append(strdecode.lower().strip())\n",
        "\n",
        "train_claims = []\n",
        "for fact in train_data:\n",
        "        strencode = fact[\"claim\"].encode(\"ascii\", \"ignore\")\n",
        "        strdecode = strencode.decode()\n",
        "        train_claims.append(strdecode.lower().strip())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjKHl1Nklpxi",
        "outputId": "51190a12-fa46-443a-afb3-32363826450d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "377"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(val_claims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1506"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_claims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import json\n",
        "# with open(\"../../data/English/train_claims_quantemp.json\") as f:\n",
        "#   train_data = json.load(f)\n",
        "# len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "-SLsXKAUlcu7"
      },
      "outputs": [],
      "source": [
        "# train_claims = []\n",
        "# for fact in train_data:\n",
        "#         strencode = fact[\"claim\"].encode(\"ascii\", \"ignore\")\n",
        "#         strdecode = strencode.decode()\n",
        "#         train_claims.append(strdecode.lower().strip())\n",
        "# '''\n",
        "# for claim in train_claims:\n",
        "#   if claim in test_claims:\n",
        "#     print(claim)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISKaA20X5XJq",
        "outputId": "b9b29a83-ed95-4814-fea2-ce69a871e70a"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# with open(\"../../data/English/decomposed_questions_with_mapped_bm25_evidence/train_claimdecomp_evidence_question_mapping.json\") as f:\n",
        "#   train_data = json.load(f)\n",
        "# len(train_data\n",
        "#     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0apWnqA85eep",
        "outputId": "4aaeca9c-0771-4621-8fdc-a51ab2b6a33c"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# with open(\"../../data/English/decomposed_questions_with_mapped_bm25_evidence/val_claimdecomp_evidence_question_mapping.json\") as f:\n",
        "#   val_data = json.load(f)\n",
        "# len(val_data\n",
        "#     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD0NZfDFkvW1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT-q3h48kxdg",
        "outputId": "00f66565-df9d-4357-a283-6d03de807438"
      },
      "outputs": [],
      "source": [
        "\n",
        "#val_data[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "7cYv6F4Nk4SJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "LE = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "3XKkVcC8lF6t"
      },
      "outputs": [],
      "source": [
        "def get_features(data2):\n",
        "  features = []\n",
        "  for index, fact in enumerate(data2):\n",
        "    claim = fact[\"claim\"]\n",
        "    evidences = []\n",
        "    #for doc in fact[\"docs\"]:\n",
        "      #if len(question[\"top_k_doc\"])>0:\n",
        "    #evidences.append(doc)\n",
        "    evidences.append(fact[\"doc\"])\n",
        "      #questions.append(question[\"questions\"])\n",
        "    #questions = list(set(questions))\n",
        "    evidences = list(set(evidences))\n",
        "    feature = \"[Claim]:\"+claim+\"[Evidences]:\"+\" \".join(evidences)\n",
        "    features.append(feature)\n",
        "  return features\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'claim': 'Correos te pide 1,4â¬ por desinfectarte los paquetes',\n",
              " 'crawled_date': '2020-04-25',\n",
              " 'country_of_origin': 'spain',\n",
              " 'doc': ' | 6 min lectura Nos habÃ©is preguntado por otro mensaje relacionado con la marca espaÃ±ola de automÃ³viles SEAT y respiradores. En este habla un supuesto trabajador en nombre del empresa diciendo que la automovilÃ­stica estÃ¡ esperando a que los hospitales espaÃ±oles les pidan respiradores, y ofrecerÃ­a un manual de instrucciones de los mismos. Adjunta ademÃ¡s una direcciÃ³n de correo electrÃ³nico y un telÃ©fono. Este mensaje es falso. AsÃ­ lo ha desmentido la compaÃ±Ã­a a Newtral.es. Ni han lanzado ninguna campaÃ±a similar, ni estÃ¡n teniendo problemas de distribuciÃ³n de los aparatos sanitarios. Una cadena de WhatsApp supuestamente proveniente de la Guardia Civil recomienda desinstalar la aplicaciÃ³n de videoconferencia Zoom, ademÃ¡s de eliminar la cuenta. La cadena adjunta un tuit enviado por la cuenta oficial de la Guardia Civil. Sin embargo el tuit no dice eso, por tanto se trata de un mensaje falso. La pregunta a Dulceida en el Orgullo sacada de contexto La Guardia Civil tuiteÃ³ este 10 de abril que este mensaje de WhatsApp es un bulo âque aprovecha un tuit de la Guardia Civil y la actualizaciÃ³n de seguridad de Zoom para usuarios de Windows para generar alarma socialâ. Es decir, que el tuit citado por la cadena no decÃ­a nada lo que contiene el texto. Circula por diferentes redes sociales un audio criticando al Gobierno en su gestiÃ³n de la crisis sanitaria. El archivo va acompaÃ±ado de un texto que asegura que el autor del mensaje grabado es el exministro socialista del Interior JosÃ© Luis Corcuera. Ese dato es falso: se trata de un locutor de radio. Walter GarcÃ­a Carro publicÃ³ un tuit reclamando la autorÃ­a del audio viral. En otro post de esta red social publicÃ³ un link a una plataforma en la que estÃ¡ colgado el programa entero al que pertenece el fragmento que tanto se ha viralizado. Desde fÃ¡rmacos hasta remedios caseros: los mitos sobre cÃ³mo evitar la resaca que contradicen la evidencia cientÃ­fica Nos preguntÃ¡is por una serie de mensajes que atribuyen al Gobierno la autorÃ­a y difusiÃ³n de unas lÃ­neas temporales que mostrarÃ­an cuÃ¡ndo podrÃ­an ir reabriendo los comercios. Son falsas: no han salido del Gobierno. Un archivo compartido por WhatsApp llamado Fechas de apertura: (calendario tentativo que maneja el gobierno) es falsamente atribuido al Gobierno. AsÃ­ nos lo han desmentido fuentes del propio organismo a Newtral.es. Circula un mensaje de Correos que solicita el pago de 1,40 euros para desinfectar tu paquete antes de recibirlo. Este mensaje es falso: se trata de phishing, una tÃ©cnica para robar datos bancarios. Correos jamÃ¡s pedirÃ¡ pagos de ninguna cantidad a travÃ©s de email o SMS. Siempre lo harÃ¡n en la oficina o en el momento de la entrega. Circula por redes sociales un vÃ­deo situado en HungrÃ­a segÃºn algunas versiones y en EspaÃ±a segÃºn otras. TambiÃ©n se dice que esas imÃ¡genes fueron grabadas durante los estados de alarma de los respectivos paÃ­ses por el coronavirus. Â¿QuÃ© hay de cierto en estos textos? Nada. El contexto que se le da estas imÃ¡genes es falso. En BakÃº, capital de AzerbaiyÃ¡n, se produjo el pasado 19 de octubre una manifestaciÃ³n contra la corrupciÃ³n y en solicitud de unas elecciones libres. La policÃ­a azerÃ­ respondiÃ³ con al menos 60 detenciones. De ahÃ­ es donde se sacaron las imÃ¡genes que se comparten como hÃºngaras o espaÃ±olas. Circula un mensaje por WhatsApp con pautas a seguir en caso de fallecimiento de un familiar por COVID-19. Mucha de la informaciÃ³n que se da es errÃ³nea. Entre otras cosas, el mensaje asegura que la COVID-19 es una enfermedad profesional. El Real Decreto 1299/2006 recoge las consideradas enfermedades profesionales, y el coronavirus no se encuentra entre ellas. Circula un documento con un sello de la Guardia Civil con supuestos procedimientos que deben seguir algunos negocios, como el del taxi o el de la peluquerÃ­a; o regulaciones tales como la prohibiciÃ³n del uso de espacios comunes entre vecinos. Este documento, sin embargo, es falso. AsÃ­ lo ha desmentido la Guardia Civil en su cuenta oficial de Twitter, adjuntando un link al autÃ©ntico Real Decreto que establece quÃ© actividades se pueden desarrollar y en quÃ© condiciones. Recuerda que los pantallazos, fotografÃ­as y demÃ¡s copias se pueden manipular. Si quieres conocer este tipo de informaciones, acude sola y directamente a fuentes oficiales. Un vÃ­deo compartido mÃ¡s de mil veces en Facebook muestra a un hombre que se corta el cuello mientras huye de la policÃ­a. El tÃ­tulo del vÃ­deo lleva a pensar que ha sido grabado en EspaÃ±a y afirma que es durante la cuarentena. Ambos datos son falsos: ni sucede en EspaÃ±a, ni es actual. Varios medios serbios publicaron un suicidio de un hombre mientras huÃ­a de la policÃ­a serbia por la calle Alejandro I de Yugoslavia durante el pasado mes de enero, Ã©poca durante la cual Serbia no habÃ­a registrado casos de coronavirus ni estaba, mucho menos, en estado de alarma. Circula por WhatsApp una captura de pantalla de otro mensaje de la misma aplicaciÃ³n de mensajerÃ­a que afirma que âa partir del lunesâ la Junta de Extremadura permitirÃ¡ salir a pasear por las avenidas. A continuaciÃ³n viene un link, el cual, al ser una captura de pantalla, no se puede pinchar. Al introducir la direcciÃ³n en el navegador, vemos que es broma. Por tanto, el mensaje es falso. Pese a que el link del mensaje lleve a una imagen de un gorila, nos hemos puesto en contacto con la Junta, desde donde nos confirman que se trata de un bulo.',\n",
              " 'fact_source': 'newtral',\n",
              " 'factchecker': ['Por Newtral'],\n",
              " 'label': 'False',\n",
              " 'url': 'https://www.newtral.es/covid-19-epidemia-mundial-de-bulos-2/20200425/',\n",
              " 'lang': 'es',\n",
              " 'numerical': True,\n",
              " 'taxonomy_label': 'statistical'}"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "qY7Gux6Yn5rI"
      },
      "outputs": [],
      "source": [
        "train_features = get_features(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ5AoF54oV2t",
        "outputId": "7867da60-f74f-4715-b1c1-8926f8ede44e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1204"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "FHml9DUHn_bh",
        "outputId": "fc92676b-7bf7-4e74-e1aa-dcb86dbb41fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[Claim]:Una pareja senegalesa inventÃ³ 18 hijos y defraudÃ³ 360.000 euros en ayudas sociales en EspaÃ±a[Evidences]:\"RecordÃ¡is la pareja senegalesa que defraudÃ³ 360.000 â¬ en ayudas, fingiendo tener 18 hijos. Pues la han condenado a pagar dos euros. Si fueran espaÃ±oles, van 10 aÃ±os a la cÃ¡rcel\". Con mensajes como este se difunde el caso de una pareja que fingiÃ³ tener 18 hijos y defraudÃ³ 360.000 euros en ayudas sociales afirmando que es senegalesa y que ocurriÃ³ en EspaÃ±a. Es un bulo: el caso ocurriÃ³ en Sunderland (Reino Unido) y la pareja no es senegalesa, sino inglesa.  Una foto publicada por medios ingleses de la pareja, Tracy Ashbridge y Robert Ashbridge de Sunderland, Inglaterra, condenados por fraude de 360.000 euros en ayudas sociales.  El caso ocurriÃ³ en Sunderland (Reino Unido) y la pareja no es senegalesa, sino inglesa  Estos contenidos se difunden con capturas de titulares en medios donde no se afirma ni la nacionalidad de los acusados ni el lugar en el que ocurriÃ³. Pero es un caso que ocurriÃ³ en Inglaterra. La acusada, Tracy Ashbridge es funcionaria en la Agencia de RecaudaciÃ³n y Aduanas de Su Majestad (HMRC por sus siglas en inglÃ©s), que es similar a la Agencia Tributaria en EspaÃ±a. UtilizÃ³ su posiciÃ³n en el trabajo para alterar los datos de antiguos demandantes legÃ­timos para conseguir dinero, segÃºn el medio inglÃ©s Sunderland Echo. Ashbridge utilizÃ³ un total de nueve cuentas bancarias para recibir los pagos entre 2015 y 2019.  El Tribunal de la Corona de Newcastle condenÃ³ a la mujer y a su marido, Robert Ashbridge, ambos ingleses, a devolver solo dos libras, lo que equivale a cerca de cuatro euros, segÃºn mencionÃ³ el Daily Mail.  Por lo tanto, es un bulo, no estÃ¡ relacionado con la inmigraciÃ³n ni con EspaÃ±a: el caso ocurriÃ³ en Sunderland (Reino Unido) y la pareja no es senegalesa, sino inglesa.'"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_features[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "SeHEwL3doMD6"
      },
      "outputs": [],
      "source": [
        "val_features = get_features(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ-ipHaHoiY-",
        "outputId": "23a44b5f-7ae4-4128-8926-135607b2d3b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "302"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(val_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Iyh75sm2ok_6",
        "outputId": "b717a62e-0ed3-4c61-c654-cf3a6def966b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[Claim]:Tomado de una cÃ¡mara instalada en una de las casas donde ocurriÃ³ la erupciÃ³n del volcÃ¡n de Isla Blanca en Nueva Zelanda el 9 de diciembre del 2019 donde 18 personas perdieron la vida[Evidences]: | 2 min lectura EstÃ¡ volviendo a circular por redes sociales un vÃ­deo que supuestamente muestra la erupciÃ³n del volcÃ¡n Isla Blanca, en Nueva Zelanda. Las imÃ¡genes compartidas exhiben un mar tranquilo en el que de repente se produce una explosiÃ³n submarina que genera una nube de humo que se expande rÃ¡pidamente y acaba cegando la cÃ¡mara. Sin embargo, el vÃ­deo no es real, sino que se trata de una simulaciÃ³n. TambiÃ©n nos habÃ©is enviado a travÃ©s de nuestro servicio de verificaciÃ³n por WhatsApp (+34 627 28 08 15) estas mismas imÃ¡genes acompaÃ±adas de un mensaje que indica que se trata de un vÃ­deo âtomado de una cÃ¡mara instalada en una de las casas donde ocurriÃ³ la erupciÃ³n del volcÃ¡n de Isla Blanca el 9 de diciembre del 2019, donde 18 personas perdieron la vidaâ. Es cierto que el 9 de diciembre de 2019 se produjo en Nueva Zelanda la erupciÃ³n del volcÃ¡n Isla Blanca, que provocÃ³ la muerte de mÃ¡s de 20 personas. Pero el vÃ­deo compartido no muestra este hecho, sino que se trata de una simulaciÃ³n en 3D para el Museo Memorial de la Guerra de Auckland. El vÃ­deo no muestra la erupciÃ³n del volcÃ¡n Isla Blanca, en Nueva Zelanda Este mismo bulo ya lo desmentimos en Newtral.es en febrero de 2020. Se trata de una simulaciÃ³n 3D realizada para el Museo Memorial de la Guerra de Auckland, y que hemos encontrado publicado por primera vez hace diez aÃ±os. Este mismo vÃ­deo puede ser encontrado en la cuenta de Vimeo de la empresa Brandspank, publicado en 2011. En la descripciÃ³n del mismo explican que se trata de un vÃ­deo diseÃ±ado âpara simular la vista de un salÃ³n de Aucklandâ que muestra âuna representaciÃ³n realista de un evento catastrÃ³ficoâ. La misma secuencia se puede encontrar en el canal de YouTube del Museo Memorial de la Guerra de Auckland. El vÃ­deo fue publicado el 19 de diciembre de 2019 y en la descripciÃ³n del mismo se indica que se trata de âuna simulaciÃ³n educacional de un terremoto causado por una erupciÃ³n volcÃ¡nicaâ. Este vÃ­deo forma parte de la exposiciÃ³n de volcanes del museo, como se puede comprobar en la misma web de la instituciÃ³n. Sobre esta pieza, el museo invita a sentarse âen el salÃ³n del 7A Puia St, St Heliersâ y observar âuna terrorÃ­fica erupciÃ³n en el puerto de Auckland desde una casaâ. La erupciÃ³n del volcÃ¡n Isla Blanca SÃ­ que es cierto, como se indica en el mensaje que acompaÃ±a a este vÃ­deo, que el 9 de diciembre de 2019 el volcÃ¡n de Isla Blanca entrase en erupciÃ³n, matando a varias personas. My god, White Island volcano in New Zealand erupted today for first time since 2001. My family and I had gotten off it 20 minutes before, were waiting at our boat about to leave when we saw it. Boat ride home tending to people our boat rescued was indescribable. #whiteisland pic.twitter.com/QJwWi12Tvt â Michael Schade (@sch) December 9, 2019 SegÃºn indica la BBC, en el momento de la erupciÃ³n del volcÃ¡n Isla Blanca âhabÃ­a unas 50 personas cerca del lugar, incluso caminando cerca del crÃ¡terâ. En un primer momento se anunciaron 16 fallecidos, y 20 personas se encontraban en cuidados intensivos. Pero en noviembre de 2020 la policÃ­a de Nueva Zelanda aÃ±adiÃ³ un nuevo fallecido a causa de las heridas provocadas por la erupciÃ³n del volcÃ¡n, llegando a 22 el nÃºmero de fallecidos por la erupciÃ³n.'"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_features[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['claim', 'crawled_date', 'country_of_origin', 'doc', 'fact_source', 'factchecker', 'label', 'url', 'lang', 'numerical', 'taxonomy_label'])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "98BSyfIZontr"
      },
      "outputs": [],
      "source": [
        "train_labels = [fact[\"label\"] for fact in train_data]\n",
        "val_labels = [fact[\"label\"] for fact in val_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJYf-sJ4pHCd",
        "outputId": "621cbd28-c0d2-4849-c08d-07d8cb793ac4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 1, 1, 1], dtype=int64)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels_final = LE.fit_transform(train_labels)\n",
        "train_labels_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cjPop6cpdiA",
        "outputId": "832584fd-0ada-4b9c-b594-ee080c32b21a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
              "      dtype=int64)"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels_final[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dO586pApTPH",
        "outputId": "c1d079a7-80ff-424b-d428-e7c07b562aa3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
              "       2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 0, 1, 0, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "       2, 1, 1, 0, 2, 2, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 2, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1,\n",
              "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1,\n",
              "       1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 2, 1, 1, 0, 1, 2, 0,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1])"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_labels_final = LE.transform(val_labels)\n",
        "val_labels_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDzDVC1lnmwD",
        "outputId": "40f26153-87d4-4180-cdef-8ad006a4bc2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'claim': 'ABC tuitea que cuatro de cada cinco jÃ³venes del colectivo LGTBI se sentirÃ­an mÃ¡s protegidos en un paÃ­s islÃ¡mico que en una EspaÃ±a gobernada por Vox',\n",
              " 'crawled_date': '2024-04-20T03:15:56',\n",
              " 'country_of_origin': None,\n",
              " 'doc': '\"Cuatro de cada cinco jÃ³venes pertenecientes al colectivo LGTB reconocen que se sentirÃ­an mÃ¡s protegidos en un paÃ­s islÃ¡mico que en una EspaÃ±a gobernada por Vox\". Este es el mensaje que se estÃ¡ difundiendo en Twitter (ahora X) como si lo hubiera publicado ABC. Es un bulo. La cuenta que lo publica no es la de ABC, sino @Santodebot, un perfil del que ya hemos desmentido otros contenidos y que en su biografÃ­a se define como \"parodia\".  Este es el contenido que se difunde:  Captura del bulo que se difunde.  La cuenta que lo publica no es la de ABC  El tuit se difunde como si lo hubiera publicado el diario ABC, con mensajes como estos: \"La propaganda ha calado bien hondo entonces\" o \"esto es producto del adoctrinamiento\".  Si nos fijamos en la cuenta vemos que tiene el nombre y la foto de perfil de ABC. Pero el handle (el nombre que va detrÃ¡s de la arroba) es @Santodebot, mientras que el del diario es @abc_es.  AdemÃ¡s, en su biografÃ­a aÃ±ade que se trata de una cuenta \"parodia\". El perfil fue creado en mayo de 2019 y tiene algo mÃ¡s de 14.000 seguidores. En cambio, la cuenta de ABC se creÃ³ en 2009 y cuenta con mÃ¡s de dos millones de seguidores.  Cuenta del usuario @Santodebot y de ABC.  AdemÃ¡s, no hay rastro de que ABC haya hecho esta supuesta publicaciÃ³n ni en su web ni a travÃ©s de sus redes sociales.  En definitiva, es un bulo que ABC haya tuiteado que \"cuatro de cada cinco jÃ³venes\" del colectivo LGTBI \"se sentirÃ­an mÃ¡s protegidos en un paÃ­s islÃ¡mico que en una EspaÃ±a gobernada por Vox\". La cuenta que lo difunde es @Santodebot, de la que ya hemos desmentido otros contenidos y que se autodefine como \"parodia\".',\n",
              " 'fact_source': 'maldita_es',\n",
              " 'factchecker': 'maldita.es',\n",
              " 'label': 'False',\n",
              " 'url': 'https://maldita.es/malditobulo/20240419/abc-jovenes-lgtbi-pais-islamico-vox/',\n",
              " 'lang': 'es',\n",
              " 'numerical': True,\n",
              " 'taxonomy_label': 'comparison'}"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_data[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FardkyUtyT2B",
        "outputId": "0900fe52-1942-4cdf-9787-59f90228dd40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "302"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(val_labels_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9xEVEmzpcSS",
        "outputId": "784f720d-4b1e-49e2-b9fa-bc1d706db66a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  [Claim]:Correos te pide 1,4â¬ por desinfectarte los paquetes[Evidences]: | 6 min lectura Nos habÃ©is preguntado por otro mensaje relacionado con la marca espaÃ±ola de automÃ³viles SEAT y respiradores. En este habla un supuesto trabajador en nombre del empresa diciendo que la automovilÃ­stica estÃ¡ esperando a que los hospitales espaÃ±oles les pidan respiradores, y ofrecerÃ­a un manual de instrucciones de los mismos. Adjunta ademÃ¡s una direcciÃ³n de correo electrÃ³nico y un telÃ©fono. Este mensaje es falso. AsÃ­ lo ha desmentido la compaÃ±Ã­a a Newtral.es. Ni han lanzado ninguna campaÃ±a similar, ni estÃ¡n teniendo problemas de distribuciÃ³n de los aparatos sanitarios. Una cadena de WhatsApp supuestamente proveniente de la Guardia Civil recomienda desinstalar la aplicaciÃ³n de videoconferencia Zoom, ademÃ¡s de eliminar la cuenta. La cadena adjunta un tuit enviado por la cuenta oficial de la Guardia Civil. Sin embargo el tuit no dice eso, por tanto se trata de un mensaje falso. La pregunta a Dulceida en el Orgullo sacada de contexto La Guardia Civil tuiteÃ³ este 10 de abril que este mensaje de WhatsApp es un bulo âque aprovecha un tuit de la Guardia Civil y la actualizaciÃ³n de seguridad de Zoom para usuarios de Windows para generar alarma socialâ. Es decir, que el tuit citado por la cadena no decÃ­a nada lo que contiene el texto. Circula por diferentes redes sociales un audio criticando al Gobierno en su gestiÃ³n de la crisis sanitaria. El archivo va acompaÃ±ado de un texto que asegura que el autor del mensaje grabado es el exministro socialista del Interior JosÃ© Luis Corcuera. Ese dato es falso: se trata de un locutor de radio. Walter GarcÃ­a Carro publicÃ³ un tuit reclamando la autorÃ­a del audio viral. En otro post de esta red social publicÃ³ un link a una plataforma en la que estÃ¡ colgado el programa entero al que pertenece el fragmento que tanto se ha viralizado. Desde fÃ¡rmacos hasta remedios caseros: los mitos sobre cÃ³mo evitar la resaca que contradicen la evidencia cientÃ­fica Nos preguntÃ¡is por una serie de mensajes que atribuyen al Gobierno la autorÃ­a y difusiÃ³n de unas lÃ­neas temporales que mostrarÃ­an cuÃ¡ndo podrÃ­an ir reabriendo los comercios. Son falsas: no han salido del Gobierno. Un archivo compartido por WhatsApp llamado Fechas de apertura: (calendario tentativo que maneja el gobierno) es falsamente atribuido al Gobierno. AsÃ­ nos lo han desmentido fuentes del propio organismo a Newtral.es. Circula un mensaje de Correos que solicita el pago de 1,40 euros para desinfectar tu paquete antes de recibirlo. Este mensaje es falso: se trata de phishing, una tÃ©cnica para robar datos bancarios. Correos jamÃ¡s pedirÃ¡ pagos de ninguna cantidad a travÃ©s de email o SMS. Siempre lo harÃ¡n en la oficina o en el momento de la entrega. Circula por redes sociales un vÃ­deo situado en HungrÃ­a segÃºn algunas versiones y en EspaÃ±a segÃºn otras. TambiÃ©n se dice que esas imÃ¡genes fueron grabadas durante los estados de alarma de los respectivos paÃ­ses por el coronavirus. Â¿QuÃ© hay de cierto en estos textos? Nada. El contexto que se le da estas imÃ¡genes es falso. En BakÃº, capital de AzerbaiyÃ¡n, se produjo el pasado 19 de octubre una manifestaciÃ³n contra la corrupciÃ³n y en solicitud de unas elecciones libres. La policÃ­a azerÃ­ respondiÃ³ con al menos 60 detenciones. De ahÃ­ es donde se sacaron las imÃ¡genes que se comparten como hÃºngaras o espaÃ±olas. Circula un mensaje por WhatsApp con pautas a seguir en caso de fallecimiento de un familiar por COVID-19. Mucha de la informaciÃ³n que se da es errÃ³nea. Entre otras cosas, el mensaje asegura que la COVID-19 es una enfermedad profesional. El Real Decreto 1299/2006 recoge las consideradas enfermedades profesionales, y el coronavirus no se encuentra entre ellas. Circula un documento con un sello de la Guardia Civil con supuestos procedimientos que deben seguir algunos negocios, como el del taxi o el de la peluquerÃ­a; o regulaciones tales como la prohibiciÃ³n del uso de espacios comunes entre vecinos. Este documento, sin embargo, es falso. AsÃ­ lo ha desmentido la Guardia Civil en su cuenta oficial de Twitter, adjuntando un link al autÃ©ntico Real Decreto que establece quÃ© actividades se pueden desarrollar y en quÃ© condiciones. Recuerda que los pantallazos, fotografÃ­as y demÃ¡s copias se pueden manipular. Si quieres conocer este tipo de informaciones, acude sola y directamente a fuentes oficiales. Un vÃ­deo compartido mÃ¡s de mil veces en Facebook muestra a un hombre que se corta el cuello mientras huye de la policÃ­a. El tÃ­tulo del vÃ­deo lleva a pensar que ha sido grabado en EspaÃ±a y afirma que es durante la cuarentena. Ambos datos son falsos: ni sucede en EspaÃ±a, ni es actual. Varios medios serbios publicaron un suicidio de un hombre mientras huÃ­a de la policÃ­a serbia por la calle Alejandro I de Yugoslavia durante el pasado mes de enero, Ã©poca durante la cual Serbia no habÃ­a registrado casos de coronavirus ni estaba, mucho menos, en estado de alarma. Circula por WhatsApp una captura de pantalla de otro mensaje de la misma aplicaciÃ³n de mensajerÃ­a que afirma que âa partir del lunesâ la Junta de Extremadura permitirÃ¡ salir a pasear por las avenidas. A continuaciÃ³n viene un link, el cual, al ser una captura de pantalla, no se puede pinchar. Al introducir la direcciÃ³n en el navegador, vemos que es broma. Por tanto, el mensaje es falso. Pese a que el link del mensaje lleve a una imagen de un gorila, nos hemos puesto en contacto con la Junta, desde donde nos confirman que se trata de un bulo.\n",
            "Token IDs: tensor([    0, 10975, 45699, 42645, 15228,   241,   366,  3055,   181,  1949,\n",
            "          112,     6,   306, 10851,  2953,  2694, 37597, 13775,  3774,  6044,\n",
            "        15259,   293, 10975, 25377, 31688, 42645,  1721,   231,  5251, 25673,\n",
            "         3851, 29603,  2489,   428,  1140,   354,  1198,   571,  5973,  2102,\n",
            "         2953,  1021, 19937,   475,  1290,  1176,   242,  6258,  8647,  2102,\n",
            "         2764,   897,  4401,  3245,  2714,  6709,  6303,  3019,   263, 10948,\n",
            "         1479,   705,  4755,  6324,  2571,  1423, 44266,   625,  4765,     4,\n",
            "         2271,  8002,  2489,  3662,   102,   542, 28836,   257,   990,   139,\n",
            "         2664,   873,  1176,  9618,  1177,   295,  5223,   241,  2424,  2841,\n",
            "          642, 19716,   385, 13850, 12454,  1192,   897, 10948,  1417,   718,\n",
            "         1977,   620,  2426,  3304,  1526,  2714,  1741,  5502,    10,  1192,\n",
            "         3774,  1098,   293,  2714,  6709,  6303,  7003,  7427,   181, 34343,\n",
            "        44266,   625,  4765,     6,  1423,     9,   241,  7742,  5272,   542,\n",
            "        12769,   263,  9084,  2070,  7309,  1499,   293,   263,  3774, 21230,\n",
            "          366,     4,  1614,   267, 20339,  2329,   991,  6417,   542,   102,\n",
            "        10697, 12870,  2727,   263,  9240,   241,   139, 17995,  2727,  2684,\n",
            "         1423,   542, 19676,  1140,   506, 16405,     4,   381,  6526,   475,\n",
            "         1290,  1176,   242,  2714,   856, 19726,     4,   287,  1977,  4600,\n",
            "         2489,  2694,  1757,  6005,   897,  7753,   102,  6303,  5272,    10,\n",
            "        36997,  7085,     4,   293,     4, 11568,  1368,   260, 33532,   329,\n",
            "         2102,   295,   154,  4989,  2205,   102, 14379,  1122,     6, 10265,\n",
            "         3304,  7499,  2724,   118, 12454,   936,   281,   263,  7018,  8643,\n",
            "        20296,  2727,   263,  3774,    10,  5489, 29501, 15610,   405, 24198,\n",
            "            4,  1890,   102, 12260,  4242,   263,  6861, 28836,   257,   990,\n",
            "         5511,   242,  5401,  4843,   242,   263,   897,  6137,   493,  5280,\n",
            "         3872, 18832, 15205,  2694,   179,     2])\n"
          ]
        }
      ],
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in train_features:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', train_features[0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZavNUqipvVV",
        "outputId": "31c41f1b-0026-46f9-a8dc-3629b442a544"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  [Claim]:Acaba de salir un comunicado oficial de pepsi que no consuman 7up porque le echaron Ã¡cido muriÃ¡tico por error y ya van 8 muertos[Evidences]:âAcaba de salir un comunicado oficial de pepsi que no consuman 7up porque le echaron Ã¡cido muriÃ¡tico por error y ya van 8 muertos (sic)â, dice una imagen que circula en Facebook y Whatsapp. Pero es falso, se trata de desinformaciÃ³n que circula en internet al menos de 2017. A pesar de que la imagen contiene faltas de ortografÃ­a y verificadores de otros paÃ­ses lo desmintieron en aÃ±os anteriores, usuarios de Facebook y WhatsApp compartieron recientemente la falsa alerta La empresa ya lo desmintiÃ³ El 23 de septiembre de 2017, en la pÃ¡gina oficial de Facebook del refresco 7Up se publicÃ³ un desmentido en donde narraba que el supuesto comunicado que recomendaba no consumir sus productos no era oficial y no habÃ­a sido emitido por la empresa. Aprovecharon para destacar que siguen protocolos de seguridad en sus productos y que tienen estrictos controles de calidad. Â¿De dÃ³nde saliÃ³ esta desinformaciÃ³n? El 18 de septiembre de 2017, siete personas se intoxicaron tras presuntamente beber metanfetamina lÃ­quida de un refresco 7UP de dos litros en el estado de Baja California. Una de ellas muriÃ³. Animal PolÃ­tico informÃ³ en su momento que las autoridades de Baja California incautaron un lote de poco mÃ¡s de 400 mil refrescos de 2 litros 7Up en Valle de Mexicali, tras confirmarse la intoxicaciÃ³n. TambiÃ©n levantaron una alerta sanitaria para evitar el consumo del producto. Pero en diciembre de ese mismo aÃ±o, luego de destruir el lote contaminado y realizar las investigaciones pertinentes, levantaron la veda. Al respecto, 7Up hizo un pronunciamiento en donde seÃ±alÃ³ que colaborarÃ­a con las autoridades en la investigaciÃ³n. Sin embargo, con el paso de los aÃ±os esta situaciÃ³n se fue sacando de contexto y se convirtiÃ³ en desinformaciÃ³n que ya ha sido desmentida por verificadores de hechos de diferentes paÃ­ses como Maldito Bulo en EspaÃ±a, Colombia Check en Colombia, y Es Paja en Venezuela. Por tanto, es falso que la empresa 7Up haya emitido un comunicado para alertar a la poblaciÃ³n sobre la presencia de Ã¡cido muriÃ¡tico en sus productos.\n",
            "Token IDs: tensor([    0, 10975, 45699, 42645, 26145,  6412,   263,  6641,   853,   542,\n",
            "         3137, 26488,  2102,     9, 23092,   263,   181,  2462, 11000,  1192,\n",
            "          117, 20411,   260,   262,   658,  2953,  3407,  2084,   364,   611,\n",
            "         9303,   952,  5543,   438,  6005, 22802,   118,  1526,    90,  2684,\n",
            "         2953,  5849,  1423, 13531,  3538,   290, 14701,  2399,   366, 10975,\n",
            "        25377, 31688, 42645,    17,    48, 26145,  6412,   263,  6641,   853,\n",
            "          542,  3137, 26488,  2102,     9, 23092,   263,   181,  2462, 11000,\n",
            "         1192,   117, 20411,   260,   262,   658,  2953,  3407,  2084,   364,\n",
            "          611,  9303,   952,  5543,   438,  6005, 22802,   118,  1526,    90,\n",
            "         2684,  2953,  5849,  1423, 13531,  3538,   290, 14701,  2399,   366,\n",
            "           36, 15335,    43,    17,    46,     6, 23819,   542,   102, 26031,\n",
            "          225,  1192, 27884,  5571,  1177,   622,  1423, 35415,  3340,     4,\n",
            "         2595,   139,  2714,   856, 19726,     6,   842,  2664,  2186,   263,\n",
            "         2694,   179,  3899,  5014,  2727,  1192, 27884,  5571,  1177,  2888,\n",
            "         1076,   604,   366,   263,   193,     4,    83,   181, 19115,   263,\n",
            "         1192,   897, 26031,   225,  8541,   118,  2552,   856,  3967,   281,\n",
            "          263,    50,    90,  2154, 13883,  5272,  1423,  4342,  8685,   625,\n",
            "         4765,   263, 19313,  3985,  6044,  1977, 24151,  4600,  2694, 30732,\n",
            "          906,   261,  1177,    10,  6303,   366,    41,  1334,   118,  4765,\n",
            "            6,   201,   257, 24198,   263,   622,  1423,  6861,  7753,  2013,\n",
            "          906,   261,  3872,  4843,  6285,   242,   897, 22461,   102,  5439,\n",
            "          102,  1587,  2841,   642, 19716, 13531,  4600,  2694, 30732,   118,\n",
            "         1479,  1448,   883,   263,   842,  3320,  9173,  7805,   263,   193,\n",
            "            6,  1177,   897,   181,  1526,   571,  1243,     9, 23092,   263,\n",
            "          622,  2424, 39240,   876,   262, 10926,   842,   285,  1479,   542,\n",
            "         2694,  1757,  6005,  1177,   385,     2])\n"
          ]
        }
      ],
      "source": [
        "val_input_ids = []\n",
        "val_attention_masks = []\n",
        "\n",
        "for sent in val_features:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    val_input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    val_attention_masks.append(encoded_dict['attention_mask'])\n",
        "# Convert the lists into tensors.\n",
        "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
        "val_attention_masks = torch.cat(val_attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', val_features[0])\n",
        "print('Token IDs:', val_input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "evSioYADp_y4"
      },
      "outputs": [],
      "source": [
        "train_labels_final = torch.tensor(train_labels_final)\n",
        "val_labels_final = torch.tensor(val_labels_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Nk-HGh0yWwf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC7Tt92syW5Z",
        "outputId": "64a194d8-1181-42e3-ba59-8c9c98f2bf43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([302])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_labels_final.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLCxP_iqzspd",
        "outputId": "087ff474-3216-4443-94f5-f715b629e453"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "302"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(val_input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIo3GxyUrMml",
        "outputId": "2c75132b-6972-4fe2-90a0-6f2c4c54452f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['True', 'False', 'Conflicting']"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_classes = len(list(set(train_labels)))\n",
        "list(set(train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg90AQJcrZFD",
        "outputId": "4cba898f-d42c-41e7-85b5-66c8134a90ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPp5pBNjp35w",
        "outputId": "4d964737-d0a4-4b71-cd04-9ac07f455b4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Conflicting', 'False', 'True'], dtype='<U11')"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LE.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "KOK3P-9Gra78"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "# train_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n",
        "# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, train_labels_final)\n",
        "val_dataset = TensorDataset(val_input_ids, val_attention_masks,val_labels_final)\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "c6ALqnRkrjBN"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(\n",
        "            dataset,  # The training samples.\n",
        "            sampler = RandomSampler(dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "cKSZPwobrl8y"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "class MultiClassClassifier(nn.Module):\n",
        "    def __init__(self, bert_model_path, labels_count, hidden_dim=768, mlp_dim=500, extras_dim=100, dropout=0.1, freeze_bert=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.roberta = AutoModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, mlp_dim),\n",
        "            nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # # nn.ReLU(),\n",
        "            # # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),\n",
        "            nn.Linear(mlp_dim, labels_count)\n",
        "        )\n",
        "        # self.softmax = nn.LogSoftmax(dim=1)\n",
        "        if freeze_bert:\n",
        "            print(\"Freezing layers\")\n",
        "            for param in self.roberta.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, tokens, masks):\n",
        "        output = self.roberta(tokens, attention_mask=masks)\n",
        "        dropout_output = self.dropout(output[\"pooler_output\"])\n",
        "        # concat_output = torch.cat((dropout_output, topic_emb), dim=1)\n",
        "        # concat_output = self.dropout(concat_output)\n",
        "        mlp_output = self.mlp(dropout_output)\n",
        "        # proba = self.sigmoid(mlp_output)\n",
        "        # proba = self.softmax(mlp_output)\n",
        "\n",
        "        return mlp_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986,
          "referenced_widgets": [
            "c85dfe45916e4fd2bde577671b638545",
            "321b8c67ad514136973fa165ce1fa150",
            "93f6560dfb294ff3aa70ebdcebb68af5",
            "674626d7375845969566ab5924291510",
            "62372fc3b77d403fa1c7a951ac131486",
            "48eedc54a44f4ad0803790deca8eb1f0",
            "30765132cd1d497abb5819c90305349d",
            "0c2fa22b85374f90949a169019ee7149",
            "e63832ecd9464780905b4ee6d9cbbd3e",
            "a9eea694c39246a0943885aa1f8c1938",
            "6f1eddf15edf4496b5d90c0f5561758d",
            "ad956be746844fbaa439f5d324e609cb",
            "98afaf1a35bb4aa9be426b04a0540bd0",
            "c471c289770646de98644d2f6d8135c9",
            "83b6b0f56c5d4014a45ef9b63ec38a68",
            "2c5678d9091e428c82ba59aca17d2167",
            "9735ffcc84a5419bb48d7ea20c39de97",
            "f54200478abe490d9e9d569e72382b3a",
            "e13bfcc99d5d47a9842587576f2c8288",
            "a8ecd943344245698fd5e16d61dc45be",
            "390ecd5a1d2343ae89e3012fe8385be7",
            "4c5c165e9c354856aa268f17b8991969"
          ]
        },
        "id": "CAxysrcNsFl8",
        "outputId": "00ec8910-34dd-4aa6-b336-5d9b6bdc2ed9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at uf-aice-lab/math-roberta and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MultiClassClassifier(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (mlp): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=768, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Loads BertForSequenceClassification, the pretrained BERT model with a single\n",
        "model = MultiClassClassifier(\"uf-aice-lab/math-roberta\",num_classes, 1024,768,140,dropout=0.1,freeze_bert=False)\n",
        "\n",
        "# model.load_state_dict(torch.load(\"model_bert_difficulty_prediction/model_weights\"))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBtbVgt4QwIh"
      },
      "outputs": [],
      "source": [
        "# model.load_state_dict(torch.load(\"model_bert_difficulty_prediction/model_weights\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iilNEZRCsJjH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awQ2Y9Jb3kht",
        "outputId": "c8895c2c-a9a2-43ec-9bf7-8d09821ce216"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "2Ys-M4-e3khv"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrYqErOD3khx",
        "outputId": "3af1a631-221c-46fb-fb09-b940f3b61509"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWVSE9LM3kh0",
        "outputId": "4f0501f5-0346-47ec-e80a-d59ea67b69b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "61920"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "1935 * 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "rcvxVVi63kh3"
      },
      "outputs": [],
      "source": [
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "GUw3zm6g3kh5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "ta6zfUTa3kh7"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "GFq9gd5kQSHb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "a_nmuoSgQ5t3"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "ugVDrHu20c8G"
      },
      "outputs": [],
      "source": [
        "for param in model.roberta.encoder.layer[0:5].parameters():\n",
        "    param.requires_grad=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "E1rDO58zMfc8"
      },
      "outputs": [],
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LhAy2hZ3kh9",
        "outputId": "4fb6e10c-af5f-4a21-df61-6acd8ea29dc1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "RobertaSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 20 ========\n",
            "Training...\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: out of memory\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[104], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Perform a forward pass (evaluate the model on this training batch).\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m probas \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb_input_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Accumulate the training loss over all of the batches so that we can\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# calculate the average loss at the end. `loss` is a Tensor containing a\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# single value; the `.item()` function just returns the Python value\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# from the tensor.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(probas, b_labels)\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[91], line 24\u001b[0m, in \u001b[0;36mMultiClassClassifier.forward\u001b[1;34m(self, tokens, masks)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens, masks):\n\u001b[1;32m---> 24\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     dropout_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpooler_output\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# concat_output = torch.cat((dropout_output, topic_emb), dim=1)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# concat_output = self.dropout(concat_output)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:976\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    974\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 976\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    989\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:631\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    620\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    621\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    622\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    628\u001b[0m         output_attentions,\n\u001b[0;32m    629\u001b[0m     )\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 631\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:520\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    510\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    517\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    519\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 520\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:447\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    439\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    446\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 447\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    456\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    457\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:313\u001b[0m, in \u001b[0;36mRobertaSdpaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m output_attentions \u001b[38;5;129;01mor\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;66;03m# TODO: Improve this warning with e.g. `model.config._attn_implementation = \"manual\"` once implemented.\u001b[39;00m\n\u001b[0;32m    306\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRobertaSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`attn_implementation=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m` when loading the model.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    312\u001b[0m     )\n\u001b[1;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m bsz, tgt_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m    325\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery(hidden_states))\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:267\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    263\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# Mask heads if we want to\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\modules\\dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Edu\\anaconda3\\envs\\clef\\lib\\site-packages\\torch\\nn\\functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1426\u001b[0m )\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss,\n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "early_stopping = EarlyStopping(patience=2, verbose=True)\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_accuracy = 0\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to\n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questimport gensim.downloader as api\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        # b_poincare = batch[2].to(device)\n",
        "        # b_difficulty = batch[3].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        # skill_labels = batch[3].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because\n",
        "        # accumulating the gradients is \"convenient while training RNNs\".\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        probas = model(b_input_ids,b_input_mask)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value\n",
        "        # from the tensor.\n",
        "        loss = loss_func(probas, b_labels)\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        # scheduler.step()\n",
        "        logits = probas.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        total_train_accuracy += flat_accuracy(logits, label_ids)\n",
        "    avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n",
        "    print(\" Train Accuracy: {0:.2f}\".format(avg_train_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        # b_poincare = batch[2].to(device)\n",
        "        # b_difficulty = batch[3].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        # skill_labels = batch[3].to(device)\n",
        "\n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "\n",
        "          logits = model(b_input_ids,b_input_mask)\n",
        "\n",
        "        # Accumulate the validation loss.\n",
        "        loss = loss_func(logits, b_labels)\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    early_stopping(avg_val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "      print(\"Early stopping\")\n",
        "      break\n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    output_dir = 'math_roberta_claimdecomp_final_continued/'\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    print(\"Saving model to %s\" % output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n",
        "\n",
        "    !rm -rf \"/content/drive/My Drive/ecir_compnumfacts/math_roberta_claimdecomp_final_continued\"\n",
        "    !mv math_roberta_claimdecomp_final_continued \"/content/drive/My Drive/ecir_compnumfacts/\"\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEdbFmsN2kAz"
      },
      "outputs": [],
      "source": [
        "tokenizer.save_pretrained(\"math_roberta_claimdecomp_final_continued_1\")\n",
        "torch.save(model.state_dict(), os.path.join(\"math_roberta_claimdecomp_final_continued_1\", 'model_weights'))\n",
        "\n",
        "!rm -rf \"/content/drive/My Drive/ecir_compnumfacts/math_roberta_claimdecomp_final_continued_1\"\n",
        "!mv math_roberta_claimdecomp_final_continued_1 \"/content/drive/My Drive/ecir_compnumfacts/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzLQ6lNltGX7"
      },
      "outputs": [],
      "source": [
        "LE.inverse_transform([0,1,2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEEKmPey0a8-"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from huggingface_hub import login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFR-s_8ZtATC"
      },
      "outputs": [],
      "source": [
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWkkt0F4Ifwc"
      },
      "outputs": [],
      "source": [
        "LE.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xy__BpY8VOQp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "clef",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "005aecb9af7446aab0512347fc4faf1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "057f6824b04047b9a64bd33c13374fdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0636f2033560480bb67985b0128a6174": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "069fac70741e46aa8455c3c68e286148": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a407fbab91d416dad54911ca5ae34f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c2fa22b85374f90949a169019ee7149": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ccf64e07be7473bad93cef52cd9d39c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d7f346bdfd1408fa34dbc0dd383a2e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7423e1a60ba34753bb14954981e6f62b",
            "placeholder": "â",
            "style": "IPY_MODEL_df59719e8bf44e1bb349f98674efefa6",
            "value": "merges.txt: 100%"
          }
        },
        "0f55c98cc4b14bbb86e5d7eecef4dd65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_005aecb9af7446aab0512347fc4faf1e",
            "placeholder": "â",
            "style": "IPY_MODEL_ca4b25ceac5c4b6c813ac9fa59b2ddce",
            "value": "tokenizer.json: 100%"
          }
        },
        "1925cff7d7544e069040f271537df7a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1db03cf091254bb6bab2c88f76916146": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "222e80b8c42d481da3a75a24960e74ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27d070e0bc0f43afb42d9f18f0b13b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1db03cf091254bb6bab2c88f76916146",
            "placeholder": "â",
            "style": "IPY_MODEL_222e80b8c42d481da3a75a24960e74ad",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 15.5MB/s]"
          }
        },
        "2c5678d9091e428c82ba59aca17d2167": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dd91549d6fc42d5a5bea3df78df29be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30765132cd1d497abb5819c90305349d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31ade0d811df4904b4de6a75a9eb3898": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7f67153d4104250a073b6f5eca34007",
              "IPY_MODEL_59620c8d958f4e2482fb8c5cf679a3b7",
              "IPY_MODEL_6e1218c6af9c4fec8c43fbcbd0d7b961"
            ],
            "layout": "IPY_MODEL_9673bee129574b1db39a8bf6dfa79be1"
          }
        },
        "321b8c67ad514136973fa165ce1fa150": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48eedc54a44f4ad0803790deca8eb1f0",
            "placeholder": "â",
            "style": "IPY_MODEL_30765132cd1d497abb5819c90305349d",
            "value": "config.json: 100%"
          }
        },
        "390ecd5a1d2343ae89e3012fe8385be7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ceb6758d9634a1197376d4e27f5e615": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e64febdc47d48ef9a185fcb5e4ce81e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_457c1f1c50aa42c3b01e9d50fdd0ec8f",
            "placeholder": "â",
            "style": "IPY_MODEL_ce09d6c4222640148d668939bab5008e",
            "value": " 456k/456k [00:00&lt;00:00, 9.54MB/s]"
          }
        },
        "41ad5d582748475e934bd6d7bbc6db88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dd91549d6fc42d5a5bea3df78df29be",
            "placeholder": "â",
            "style": "IPY_MODEL_e962acc9f7944bd6a14a899d27e5825c",
            "value": " 899k/899k [00:00&lt;00:00, 13.6MB/s]"
          }
        },
        "4272c15544ac483f99cfeb9c2046e2fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43cb251e9222448a900f03c42e58592d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "457c1f1c50aa42c3b01e9d50fdd0ec8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "483ad42b17b8441880d908d711e0c3b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f55c98cc4b14bbb86e5d7eecef4dd65",
              "IPY_MODEL_ad6ac6b0974e4699996289653def8861",
              "IPY_MODEL_27d070e0bc0f43afb42d9f18f0b13b6e"
            ],
            "layout": "IPY_MODEL_fcadec008dc54e6583a800b746d7a001"
          }
        },
        "48eedc54a44f4ad0803790deca8eb1f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bdc157bf7b3479b918cb087c4804bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c5c165e9c354856aa268f17b8991969": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59620c8d958f4e2482fb8c5cf679a3b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ccf64e07be7473bad93cef52cd9d39c",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ceb6758d9634a1197376d4e27f5e615",
            "value": 482
          }
        },
        "614599e3e614429ab0b97c69081a0e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "62372fc3b77d403fa1c7a951ac131486": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "674626d7375845969566ab5924291510": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9eea694c39246a0943885aa1f8c1938",
            "placeholder": "â",
            "style": "IPY_MODEL_6f1eddf15edf4496b5d90c0f5561758d",
            "value": " 673/673 [00:00&lt;00:00, 28.7kB/s]"
          }
        },
        "678d8a2512484175b923785849fbd605": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a6eba5085eb4de0939d33d7b9140612": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e1218c6af9c4fec8c43fbcbd0d7b961": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_678d8a2512484175b923785849fbd605",
            "placeholder": "â",
            "style": "IPY_MODEL_4272c15544ac483f99cfeb9c2046e2fa",
            "value": " 482/482 [00:00&lt;00:00, 32.4kB/s]"
          }
        },
        "6f1eddf15edf4496b5d90c0f5561758d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70b7cd65577f4afaaac2dc9b5ae121c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7423e1a60ba34753bb14954981e6f62b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ca9f4424bae4460a9850d4f6ff4da18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7eb5d9cacc6c41a58994a1615a44d086": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c78a28c25acc4f9b87392719681101cd",
              "IPY_MODEL_9b51530a76f94da4ae27a7f25cf27ee3",
              "IPY_MODEL_d1ef085b43794d1bb4f92acbd5f6f634",
              "IPY_MODEL_fa555a2e0115487599c31d2368b83fff",
              "IPY_MODEL_e379ef253a774d6e8125ee20495813f4"
            ],
            "layout": "IPY_MODEL_91c3323870d64d82b858dd723baeba89"
          }
        },
        "83b6b0f56c5d4014a45ef9b63ec38a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_390ecd5a1d2343ae89e3012fe8385be7",
            "placeholder": "â",
            "style": "IPY_MODEL_4c5c165e9c354856aa268f17b8991969",
            "value": " 1.42G/1.42G [00:08&lt;00:00, 252MB/s]"
          }
        },
        "8955b698cf2340e58d523a6f03e0026c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a73d2714c1342b1ab1185a74fef6198": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91c3323870d64d82b858dd723baeba89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "93f6560dfb294ff3aa70ebdcebb68af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c2fa22b85374f90949a169019ee7149",
            "max": 673,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e63832ecd9464780905b4ee6d9cbbd3e",
            "value": 673
          }
        },
        "9673bee129574b1db39a8bf6dfa79be1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9735ffcc84a5419bb48d7ea20c39de97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98afaf1a35bb4aa9be426b04a0540bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9735ffcc84a5419bb48d7ea20c39de97",
            "placeholder": "â",
            "style": "IPY_MODEL_f54200478abe490d9e9d569e72382b3a",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "9b51530a76f94da4ae27a7f25cf27ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_a8203576ad384b88895f72ee923c5ca7",
            "placeholder": "â",
            "style": "IPY_MODEL_7ca9f4424bae4460a9850d4f6ff4da18",
            "value": ""
          }
        },
        "a356d976c5bc437aba9ef1964dffbccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a63bab1fbb7f47c08404c2c8e576c8ab",
              "IPY_MODEL_e1c27f82724d40179ecb939f1bcf3e19",
              "IPY_MODEL_41ad5d582748475e934bd6d7bbc6db88"
            ],
            "layout": "IPY_MODEL_057f6824b04047b9a64bd33c13374fdc"
          }
        },
        "a5ff5c0f2e07418aace9422001961472": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db1d477460f14fce85dc2b9c3bb089e3",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9c03217bf794c309381666a45b26804",
            "value": 456318
          }
        },
        "a63bab1fbb7f47c08404c2c8e576c8ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a407fbab91d416dad54911ca5ae34f2",
            "placeholder": "â",
            "style": "IPY_MODEL_6a6eba5085eb4de0939d33d7b9140612",
            "value": "vocab.json: 100%"
          }
        },
        "a8203576ad384b88895f72ee923c5ca7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8ecd943344245698fd5e16d61dc45be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9eea694c39246a0943885aa1f8c1938": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab72101a46d64a199383b4855ba969a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d7f346bdfd1408fa34dbc0dd383a2e9",
              "IPY_MODEL_a5ff5c0f2e07418aace9422001961472",
              "IPY_MODEL_3e64febdc47d48ef9a185fcb5e4ce81e"
            ],
            "layout": "IPY_MODEL_0636f2033560480bb67985b0128a6174"
          }
        },
        "ad6ac6b0974e4699996289653def8861": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1925cff7d7544e069040f271537df7a8",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a73d2714c1342b1ab1185a74fef6198",
            "value": 1355863
          }
        },
        "ad956be746844fbaa439f5d324e609cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98afaf1a35bb4aa9be426b04a0540bd0",
              "IPY_MODEL_c471c289770646de98644d2f6d8135c9",
              "IPY_MODEL_83b6b0f56c5d4014a45ef9b63ec38a68"
            ],
            "layout": "IPY_MODEL_2c5678d9091e428c82ba59aca17d2167"
          }
        },
        "be2b1c33c0d54cd2a2e39cf52ec70957": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4563c6693d943f0923dd1db90609bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c471c289770646de98644d2f6d8135c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e13bfcc99d5d47a9842587576f2c8288",
            "max": 1421785643,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8ecd943344245698fd5e16d61dc45be",
            "value": 1421785643
          }
        },
        "c78a28c25acc4f9b87392719681101cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8955b698cf2340e58d523a6f03e0026c",
            "placeholder": "â",
            "style": "IPY_MODEL_e31fd0b45a8546e0be873fc56d35959f",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "c85dfe45916e4fd2bde577671b638545": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_321b8c67ad514136973fa165ce1fa150",
              "IPY_MODEL_93f6560dfb294ff3aa70ebdcebb68af5",
              "IPY_MODEL_674626d7375845969566ab5924291510"
            ],
            "layout": "IPY_MODEL_62372fc3b77d403fa1c7a951ac131486"
          }
        },
        "ca4b25ceac5c4b6c813ac9fa59b2ddce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce09d6c4222640148d668939bab5008e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1ef085b43794d1bb4f92acbd5f6f634": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_d849148804c747c8aba9cbda38accd67",
            "style": "IPY_MODEL_be2b1c33c0d54cd2a2e39cf52ec70957",
            "value": true
          }
        },
        "d7f67153d4104250a073b6f5eca34007": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8158a7b594e42b29a18c54aefd2c045",
            "placeholder": "â",
            "style": "IPY_MODEL_70b7cd65577f4afaaac2dc9b5ae121c7",
            "value": "config.json: 100%"
          }
        },
        "d849148804c747c8aba9cbda38accd67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db1d477460f14fce85dc2b9c3bb089e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df59719e8bf44e1bb349f98674efefa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e13bfcc99d5d47a9842587576f2c8288": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1c27f82724d40179ecb939f1bcf3e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4563c6693d943f0923dd1db90609bfb",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_069fac70741e46aa8455c3c68e286148",
            "value": 898823
          }
        },
        "e31fd0b45a8546e0be873fc56d35959f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e379ef253a774d6e8125ee20495813f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffd4ff391ded454299848594a048f6c7",
            "placeholder": "â",
            "style": "IPY_MODEL_43cb251e9222448a900f03c42e58592d",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "e63832ecd9464780905b4ee6d9cbbd3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8158a7b594e42b29a18c54aefd2c045": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e962acc9f7944bd6a14a899d27e5825c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9c03217bf794c309381666a45b26804": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f54200478abe490d9e9d569e72382b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa555a2e0115487599c31d2368b83fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_4bdc157bf7b3479b918cb087c4804bdc",
            "style": "IPY_MODEL_614599e3e614429ab0b97c69081a0e18",
            "tooltip": ""
          }
        },
        "fcadec008dc54e6583a800b746d7a001": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffd4ff391ded454299848594a048f6c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
